# 机器学习原理解释

> 原文：<https://www.freecodecamp.org/news/machine-learning-principles-explained/>

## **学习是表征、评估和优化的结果**

近年来，机器学习领域出现了爆炸式增长，研究人员开发了大量可供选择的算法。尽管有各种各样的模型可供选择，但它们都可以提炼为三个组成部分。

构成机器学习模型的三个组件是表示、评估和优化。这三个与监督学习最直接相关，但是它也可以与非监督学习相关。

****表示****——这描述了你想如何看待你的数据。有时，您可能希望根据个体(如 k 近邻)或图形(如贝叶斯网络)来考虑您的数据。

****评估****——出于监督学习的目的，你需要对你的学习者做得如何进行评估或打分，以便改进。使用评估函数(也称为*目标函数*或*评分函数*)来完成该评估。例子包括准确性和平方误差。

****优化**** -使用上面的评估函数，您需要使用一种优化技术从该评估函数中找到得分最高的学习者。例如贪婪搜索和梯度下降。

## **概括是关键**

机器学习的力量来自于不必硬编码或显式定义描述你的训练数据和看不见的数据的参数。这是机器学习的基本目标:概括学习者的发现。

为了测试一个学习者的概括能力，你需要一个单独的测试数据集，这个数据集在训练学习者的过程中没有使用过。这可以通过将整个训练数据集拆分为一个训练集和一个测试集来创建，也可以通过收集更多数据来创建。如果学习者使用在测试数据集中找到的数据，这将在你的学习者中产生一种比现实中做得更好的偏见。

了解你的学习者在测试数据集上会做什么的一个方法是进行所谓的 ****交叉验证**** 。这将把您的训练数据随机分成给定数量的子集(例如，10 个子集)，并留下一个子集，而学习者对其余子集进行训练。然后一旦学习者已经被训练，被遗漏的数据集被用于测试。这种训练，留下一个子集，测试是重复的，因为你轮流通过子集。

## **小心过度配合**

如果一个学习算法很好地符合给定的训练集，这并不简单地表明一个好的假设。当假设函数 J(θ)与您的训练集过于接近，在训练集上具有高方差和低误差，而在任何其他数据上具有高测试误差时，就会发生过度拟合。

换句话说，如果在用于训练参数的数据集上测量的假设误差恰好低于任何其他数据集上的误差，则发生过拟合。

### **选择最佳多项式次数**

为假设函数选择正确的多项式次数对于避免过度拟合非常重要。这可以通过测试多项式的每一次并观察数据集不同部分对误差结果的影响来实现。因此，我们可以将我们的数据集分解成 3 个部分，这 3 个部分可用于优化假设的θ和多项式次数。

数据集的一个好的分解比例是:

*   训练集:60%
*   交叉验证:20%
*   测试集:20%

因此，三个误差值可以通过以下方法计算:

1.  使用每个多项式次数的训练集来优化`Θ`中的参数
2.  使用交叉验证集找到误差最小的多项式次数
3.  使用测试集来估计泛化误差

### **修复过拟合的方法**

以下是解决过度拟合的一些方法:

1.  获取更多培训示例
2.  尝试一组较小的功能
3.  增加参数`λ lambda`