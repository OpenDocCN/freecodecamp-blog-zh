# DevOps 初学者工程课程

> 原文：<https://www.freecodecamp.org/news/devops-engineering-course-for-beginners/>

DevOps 是你在软件公司能得到的薪酬最高的职位之一。即使你不是 DevOps，知道它是如何工作的也会让你成为一个更有生产力的开发者。

我们刚刚在 freeCodeCamp.org YouTube 频道上发布了一个 DevOps 工程课程。在这个面向初学者的综合课程中，通过三个技术教程了解关于 DevOps 的所有内容。

科林·沙特尔创建了这门课程。他是 LayerCI 的联合创始人兼首席执行官。

您将了解什么是 DevOps、持续集成、持续部署策略和应用性能管理。许多 DevOps 实践常用于编程和 web 开发，理解关键术语和技术非常重要。

本课程经常引用 MERN (MongoDB，Express JS，React JS，Node JS)技术栈。您将获得一系列基于这些最佳实践的技术建议。在这些讲座中会有几个编程示例。只要你知道编码和网络的绝对基础，你就不会有任何问题。

本课程包括以下几个部分:

### 单元 1 -代码审查自动化

*   第一课什么是 DevOps？
*   第 2 课-什么是测试驱动开发(TDD)？
*   第 3 课-什么是持续集成(CI)？w/ CI 设置教程
*   第 4 课-什么是代码覆盖率？
*   第 5 课-林挺最佳实践
*   第 6 课-短暂环境，带设置教程

### 第 2 单元-部署策略

*   第 7 课-虚拟机与容器
*   第 8 课-滚动部署
*   第 9 课-带连续部署设置教程的蓝/绿部署
*   第 10 课-什么是自动缩放？
*   第 11 课-什么是服务发现？

### 第 3 单元-应用性能管理(APM)

*   第 12 课-什么是日志聚合？
*   第 13 课-重要生产指标

观看以下全部课程或在 freeCodeCamp.org YouTube 频道观看[(2 小时观看)。](https://youtu.be/j5Zsa_eOXeY)

[https://www.youtube.com/embed/j5Zsa_eOXeY?feature=oembed](https://www.youtube.com/embed/j5Zsa_eOXeY?feature=oembed)

## 完整抄本

(注:自动生成)

本初学者 DevOps 课程是您迈向 DevOps 工程角色的第一步。它由 LayerCI 的首席执行官兼联合创始人教授。

本课程的目标是让普通开发人员和普通工程从业人员学习基本的 DevOps 概念，以便他们能够胜任 DevOps 工程角色。我们还将在简介中广泛讨论 DevOps。但除此之外，我们将主要讨论工程方面的内容。

DevOps 是一种方法学，通过持续集成用户反馈来帮助工程团队更好地构建产品。

如果你在谷歌上搜索 DevOps，你会经常看到这样的图片，这真的有助于理解 DevOps 与传统的软件开发思维方式有何不同。回到过去，软件是被开发出来的，就像在工厂里开发一样。所以任何输入都是编程，然后输出，你就有了一个可以放在 CD 上的产品，然后卖给用户。

但是自从互联网的出现，有了可持续更新的软件，发布产品和获得用户反馈并将其集成到当前产品中变得非常容易，而不是制作产品的新版本。所以像脸书这样的网站会不断升级，而不是要求你购买新版本的脸书，不像老游戏，像一些城市会要求你购买新版本的模拟城市。DevOps 将这一想法正式化，各部分正在进行规划，您可以在其中获得一组想要构建的功能。你和你的团队一起为这些功能制定一些规范，

你给它们编码。因此，您团队中的开发人员将构建这些功能，以便可以发布它们。当然，它们是建造好的。所以对于一个网站来说，你可以把源代码打包成用户浏览器可以运行的 JavaScript。对于一个视频游戏，你可以发布不同的版本，包括运行在 Linux 上的版本，运行在 Windows 上的版本和运行在浏览器上的版本。所以你拿着这些人造物品，测试它们。所以测试是自动和手动的。自动测试通常被通俗地称为持续集成。人工测试俗称质量保证，QA。

然后在测试之后，你知道，利益相关者都给出了他们的反馈，它就发布了。和持续部署策略，发布和部署都是在已知某个更改是好的之后自动发生的。这里可以实现很多自动化。在更大的团队中。你知道，有一些流行的工具，比如网飞的 Spinnaker，我们会在后面的演讲中谈到。但核心思想是你想拿着软件，你想以一种他们不会注意到有问题的方式把它发给你的用户。因此，如果有一个实验性的用户界面变化，你可以在大范围展示之前，向少数用户展示，并获得他们的反馈。同样，像脸书这样拥有数十亿用户的公司，即使 1%的用户抱怨，他们也会收到数以亿计的电子邮件，发布是建立和部署的。因此，部署意味着它被发布给你的网站用户，这将意味着它在互联网上公开访问。对于一个 CD ROM，你知道，你把你的东西捆绑到一个 CD 上，然后你把它发布到一个移动版本上，你要构建这个工件，然后把它提交到 App Store。然后 App Store 会对它进行审核，然后发布一个新的更新供用户下载。

然后你操作它。运营主要是诸如扩展、确保有足够的资源用于负载、根据需要添加更多的服务器。配置处理架构问题的东西，本质上是关于监控。所以当你的用户使用你的软件时，特别是当他们提交东西，开始工作，在你的论坛上发帖时，你要确保这些帖子都是健康的。

最后，你接受所有的反馈，并把它放回计划阶段。因此，规划阶段收集所有用户反馈，收集运营和部署团队了解的关于部署和扩展产品的所有信息。然后用它来构建新的特性，解决错误，制作新版本的后端和新版本的架构。然后继续这个循环。当人们说，我们的公司使用 DevOps，或者我们的公司是技术进步，或者我们的公司是数字化转型时，这就是他们的意思。他们的意思是，不是获取一组需求并构建一个工件，然后交付，而是获取反馈的连续循环。你知道，在这两个星期的 Scrum 周期中，通常，生产用户实际上想使用的软件，他们在生产 DevOps 工程中有一些发言权，是 DevOps 的另一个常见部分。因此，除了方法论之外，这可能是技术领导者和 CEO 关心的事情，还有一个 DevOps 工程的子领域，这通常是工程师的意思。

你知道当他们说 DevOps 的时候，那通常是当他们说 DevOps 的时候招聘广告的意思。因此，如果一份招聘启事要求一名 DevOps 工程师，你知道，他们不是要求可以计划和部署代码的人。他们主要是要求有人可以建立一个测试，发布，部署和监控。

因此，开发运维工程的三大支柱，即我们的拉动式请求自动化、部署、自动化和应用性能管理。我们会深入讨论这些细节。但是想法是，拉式请求自动化帮助开发人员更快地构建东西，并且帮助他们更快地理解他们提议的变更是否是好的。部署自动化，帮助你以一种用户不会抱怨的方式部署你的代码。再说一次，脸书有很多部署自动化，因为如果他们只是把代码扔进虚空，每次开发者做出改变，就会有数以亿计的抱怨。应用程序性能管理是确保一切正常运行的自动化。因此，自动检测停机时间，自动唤醒某人，如果你知道，该网站一夜之间关闭，自动回滚的东西，如果有一个问题。我们将在未来的会谈中详细讨论所有这些问题。

我提到的第一个支柱是拉式请求自动化，它主要与开发人员反馈周期有关。因此，开发人员通过提出这些被称为“拉”请求的原子变更集来相互分担工作。我说的原子是指，它们本身功能齐全，不需要其他东西来运行。首先，这就像如果一个开发者提出一个拉请求，他们应该期待这个改变是好的。据他们所知，这种变化满足了一些业务需求。然后他们要做的就是通过一些门。因此，组织和 pull 要求自动化，他们的目标是确保开发人员能够很快判断出他们的变更是好是坏。举个例子，如果你在一个网站上工作，开发者提出了一个添加了错别字的修改，这很容易被自动检测出来。如果你设置了一个输入错误的关卡，说如果有输入错误，就不能进行任何修改，这将是一个简单的方法来确保开发者得到关于他们修改的自动反馈。人们说拉请求，你知道，截至 2021 年，通常他们指的是 Git。所以 Git 是一项最初由 Linux 推广的技术，它帮助开发人员做出这些改变并互相分享。拉请求通常由至少一个其他程序员审查，称为代码审查，其他程序员会告诉你代码风格，会告诉提议的程序员，是否有架构问题，缩放问题，主观的东西，不容易自动化。但是 DevOps 技术堆栈也可以极大地促进这一审查过程。DevOps automation 可以帮助像林挺这样的短暂环境。在代码审查完成后，我们将进入所有这些自动化。通常，负责所提议功能的工程经理或产品经理会得到反馈。所以如果你在网站上创建一个新的按钮，你会希望是设计这个按钮的设计师，你会希望是要求创建这个按钮的产品经理。两者都会给出反馈，因为如果按钮措辞不当，放置不当，不可移动，没有响应，这些都是需要另一个合并请求的问题。因此，如果最初的合并请求在第一次被提出时就满足了所有的要求，那就太好了。因此，通常情况下，非技术人员会在必要时对拉取请求给出反馈。

那么对于 DevOps 工程师来说，什么是自动化的呢？

你可以自动化一些事情，比如

自动化测试运行，每一个变化短暂的环境，自动化安全扫描，通过审查者的通知，让正确的人在正确的时间审查它。所有这些自动化的最终目标是，开发人员应该能够提出变更，并在他们提出变更的同一天将其合并。这是一个巨大的组织优势，因为这意味着可以非常快速地修复、合并和部署关键错误，而不需要特殊的过程。这也意味着开发人员不会陷入官僚主义，他们可以在通过所有关口后提出变更，变更将被部署，他们不需要发现额外的特殊关口。因此，举例来说，如果已经设置了适当的入口和自动化，开发人员应该能够更改网页，而不必询问公司中的每个人。此网页是否用于某些工作流程。由于通过了测试和 QA 审查，新的变更被认为是好的。如果出现问题，可以在自动化中添加一个新的入口，这样将来就不会出现问题。第二个支柱是部署自动化。Stack Overflow 的创始人，2000 年的一个著名帖子，把你能一步完成构建作为开发组织的第二个最重要的问题，从那时起事情就没有真正改变过。

构建过程的效率不是部署自动化的唯一目标。然而，其他目标包括部署策略，我谈到了 Canary 部署，在这种部署中，您希望一次向一个用户显示一个特性，启动新版本的应用程序，而不会导致停机。如果你必须在升级之前关闭网站，然后打开新版本，在升级过程中访问网站的访问者会注意到停机。因此，您可以采取巧妙的部署策略来避免这种情况。最后，回滚版本以防出错。

行星很容易变得过于复杂。许多公司都有复杂的内部平台来构建和发布版本。概括地说，成功和部署自动化就是找到合适的部署工具来实现业务目标并配置它们。然后，理想世界应该有很少或没有自定义代码进行部署。因此，像 Spinnaker 和 harness 这样的现成解决方案是这类事情的绝佳起点。

最后，应用程序性能管理，即使最好的代码也可能被操作错误所拖累。有一个著名的例子，一个用户在他的帖子的末尾用栈溢出放了一堆空格。他们关闭了 Stack Overflow，这是一个非常受欢迎的开发人员网站，因为 Stack Overflow 没有以一种能够很好地处理大量空白的方式部署他们的代码。因此，即使是最好的代码，甚至是像留言板这样最简单的东西，在一篇文章的结尾有一堆空格字符，也很容易出现错误，直到生产出来才被用户发现。因此，应用程序性能管理可确保处理请求所需的时间、使用的服务器数量等指标，以及所有这些关键的运行状况指标都得到处理。如果出现问题，比如对登录页面的所有请求突然花了很长时间，相关人员会被自动通知，而不是工程师在 Twitter 上发现他们的网站关闭了。

伐木。所以当程序执行时，它会产生日志。日志通常包含关于事物状态的信息。能够映射回日志是很有用的，比如，你知道，一个用户访问了一个网站，上面有这个用户的信息。他们的 IP 地址是什么？他们的用户名是什么，他们访问了什么资源，以及使用了什么资源来实现该访问。因此，如果他们必须从数据库中加载一些东西，而数据库很慢，那么可以说，用户的体验很慢，因为他们的请求很慢。但是请求完成得很慢，因为它是从数据库中缓慢完成的。所以将这些请求一路映射到它们的组成组件是非常有用的。

监控。所以，我再次提到了指标和自动提醒人们，但采用日志和指标，如何降低速度，剩余多少内存，并决定做什么。因此，如果有大量负载，您可能会根据指标决定自动扩展服务器的数量，因此在使用时添加更多的 web 服务器。根据日志，如果有错误，您可能想要自动归档票证，以便工程师调查它们。如果有停机时间，你可能想给某人打个电话，让他醒来处理停机时间。他们可以放下一切，可以说，他们可以有一个寻呼机。那就是警醒。因此，警报是指当检测到故障时，根据指标发生了一些触发事件，一些请求或缓慢的事情是不健康的，您知道，用户会注意到性能下降，应该通知某人或应该采取一些措施，新产品，不应该一下子陷入开发运维、工程设计。所有这些我都谈到了我们对于像网飞和脸书这样的大型组织的最终目标，

视情况需要添加自动化的开发人员。一个没有用户的新公司建立了一个网站。

支柱二和支柱三本质上是无用的中断不会被任何人注意到。像停机这样的事情，不会被任何人注意到。不一定有关系。你甚至不一定需要运行自动化测试，一个有用的堆栈对某些人来说会有这样的低五，或销售或我们的产品，在那里你可以得到与其他开发人员合作的阶段环境。但是这就是你关心测试的程度，你只需要为每一个被提议的改变找到一个环境。你可以自己在人工问答环境中体验一下，看看一个团队为 10 个企业用户开发一个应用是好是坏。因此，企业用户对停机时间更加敏感。因此，测试覆盖率和营业时间警报应该是优先事项。在日志记录和日志聚合错误收集方面，有 century 和 code Cove 等用于自动测试运行的流行工具，有 bit rise 和 circle ci 等用于移动测试的工具，还有一个名为 Pedro duty 的著名工具，用于记录停机时应该通知谁。因此，在工作时间，你可能会指派一个人在当天不参加任何会议。如果出现停机，他们会放下一切来解决问题。

像 Reddit 这样的社交媒体应用可能会

使用一个大的东西组合来捕捉网站中的错误，是一种收集和查看日志的流行方式。pingdom 将检查某些页面的响应时间是否过长。launchdarkly 允许您添加功能标志。因此，您可以决定是否为某个用户组启用某个功能，是否应该以 terraform 的形式向北美或欧洲的用户显示新的登录页面，从而使部署过程自动化。因此，给定一组服务器和一组需要在服务器上运行的东西，terraform 将帮助您自动创建一个计划，以确保正确的东西在正确的地方运行。

所有这些的结论是，DevOps 工程对开发团队至关重要。通过认识到它的三个支柱，客户将会有一个困惑和失望的体验，你知道，事情会变糟，事情不会适当地扩展，事情会变得缓慢。因此，当你在扩展一个工程组织时，或者当你被聘为 DevOps 工程师时，牢记这三个支柱非常重要。新产品不需要太多自动化。然而，随着产品的成熟，用户越来越多，自动化开发运维工程和投入更多资源变得越来越重要。

早上好，代码审查自动化。让我们谈谈测试，当我们谈到持续集成和其他代码审查自动化主题时，这将是非常重要的基线信息。因此，测试驱动开发是一种编码方法，在编写代码之前先编写测试。你知道，我们将从咖啡机的角度来解释测试和测试驱动的开发。所以，在我们继续的时候，请欣赏这张漂亮的咖啡机的照片。

测试驱动开发已经持续了很长时间。它在 21 世纪初开始流行。这个想法很简单，但它需要了解事物是如何形成的，才能真正有意义。

因此，从历史上看，软件开发中的常用词，如质量保证、QA 和单元测试，都源于制造物理产品的工厂。如果你在经营一家制造咖啡机的工厂，你会测试它在不同的完工程度下的工作情况。

所以单元测试，确保单个组件独立工作。加热器能用吗？水箱能盛水吗？集成测试？确保几个组件协同工作？加热器加热水箱里的水吗？

系统端到端测试？确保一切都能协同工作？咖啡机煮一杯咖啡吗

交付给客户后的验收测试？他们对结果满意吗？他们是对按钮布局感到困惑，还是在保修期内弄坏了咖啡机？

所有这些测试都有软件类比，为了诊断问题，知道哪个组件坏了是很有用的。但是知道整个系统工作正常也是有用的。因为即使每一个单独的组件都独立工作，如果你的咖啡机没有用加热器加热水，那在制作咖啡时就会有问题。

这才是真正的测试理念。但是让我们进入测试驱动开发，这是一种建立在测试之上的方法，在过去的 10 或 20 年里变得如此流行。大多数没有使用测试驱动开发的开发人员都有类似的工作流程，他们会选择一些工作。根据我们对 DevOps 的想法，它将处于规划阶段，开发人员将在规划阶段找到一些工作，他们构建它，因此他们将编写代码，并根据这些代码进行构建。然后他们测试它。所以他们已经阅读了确保他们的代码正确运行的小脚本。如果你在做一个把两个数相加的函数，你可能会把它传递给 into，结果是 4。这将是一个很好的迹象，表明你的功能工作正常。

因此，事实证明，第一步和第三步是紧密相连的。写在最后的测试基本上是规范的，什么是成功建造一个咖啡机，它应该在五秒钟内加热。为此写一个测试。它不该冲泡有足够强度的咖啡，所以为此写一个测试，等等。测试驱动开发使用三个步骤中的相似步骤来翻转这个过程。所以首先，开发人员选择一些工作。然后他们在读代码之前写测试。所以他们编写了目前失败的测试，因为没有满足规范。然后他们编写代码，直到他们在第二步中编写的所有规范都得到满足。因此，他们可能会制定一个测试方案，如果咖啡机成功了，这个方案就会起作用，然后制造最便宜的咖啡机，满足这个测试方案。

最终结果是一样的。所以软件被构建，被测试，并且符合规格。但是在很多情况下，编写代码要容易得多。如果你首先编写测试，因为你知道你在构建什么，这迫使你考虑哪些事情是重要的，哪些事情可以放在以后的一系列改变中。

这是一个讨论测试的很快的视频。下一个视频，我们将讨论持续集成，这实际上是这一理念的 DevOps 延续。在那里见。

我们已经讨论了测试，开发人员阅读脚本，确保他们的代码在他们完成代码后继续工作。这让我们开始讨论 ci，这确实是人们在 DevOps 环境中谈论的大话题之一。ci 代表持续集成。它指的是开发人员每天多次不断地将小的变更推送到中央存储库。这些变化由自动化的计算机软件来验证，该软件运行程序员定义的测试。

我们已经复习了什么是测试。那么我们来谈谈为什么一个公司会使用 ci。

嗯，ci 实际上是自动化开发运维的第一步。想象一个非常简单的场景，一个开发人员正在开发一个程序，供一小组用户使用。

开发人员制作原始程序，发布它，项目慢慢地建立牵引力。

现在，假设一年后开发人员有一个严重的错误。

他们回到旧代码，他们说，哎呀，这真是糟糕的代码。从一年前开始，我已经成为一名更好的程序员。我真的不明白这是怎么回事。但这确实是发展的方式。程序员一年比一年好。他们必须阅读并理解他们一年前写的糟糕代码。唯一有信心对可能只有一年历史的遗留代码进行更改的方法是使用 ci

ci 提高了开发速度，因为可以放心地进行新的更改，而不必担心破坏现有的功能。只要测试通过，ci 也能减少客户流失。软件中出现问题的可能性要小得多。如果你有自动运行的综合测试。只要您得到这些复选标记，您就可以合理地确信您的应用程序的核心特性将继续工作。那么，您将如何将 ci 集成到您的开发过程中呢？首先，让我们谈谈许多开发团队使用的基于分支的开发过程。所以首先，开发人员在一个特性分支上工作。因此，他们将获取最新的文件，即在特定时间向客户展示的文件，他们将从这些文件中分支出来。因此，他们将制作文件的新副本，独立于所有其他开发人员对各种组件进行更改的工作来处理他们的功能。因此，这一功能改变了手机应用程序和网站。

然后在那个分支上，他们会把它推回到存储库，通常是 GitHub、git lab 或 Bitbucket 之类的东西。然后，该存储库将运行 ci，因此 CI 将在存储库端配置，它将运行程序员定义的所有测试。然后这些测试的结果将被附加到拉取请求中。“拉”请求是开发人员要求获取他们的代码，并将其合并到将向用户显示的中央存储库中。所以你把特征分支放在这里，

你把它放在最后，所有其他的提交都显示给用户。因此，这个提交现在是下一个将向用户显示的提交，下一次是部署，程序员遇到的功能将对用户可见。最好的一点是，它不需要像 GitHub、git lab 和 Bitbucket 这样的中央 Git 库。大多数都有大量的免费层，即使对于组织来说，也只是少了一些您可能需要的安全和访问控制、权限功能。随着规模的扩大，ci 提供者，如层 ci、GitHub actions、git lab pipelines，都有丰富的功能。你知道，他们的 ci 确实是为在网站上工作的人制作的，这可能是需要考虑的事情。但是如果您真的处于项目生命周期的早期，使用哪个 ci 提供者并不重要。当然，从 ci 的讨论中可以得出一点，ci 是一个重要的工具，它确实是大多数拉式请求自动化方案中应该自动化的第一件事。因为太简单了。无论如何，开发人员都应该编写这些测试。因此，如果你不自动地、慢慢地运行测试，人们会在没有意识到他们正在破坏的情况下破坏东西。而用户会注意到那些坏掉的东西。

遵循像特性分支和 ci 这样的最佳实践是扩展开发团队的一个非常简单的方法。仅使用 ci，一个开发团队就可以轻松地从一个开发人员扩展到 10 个开发人员。在某个时候，您将不得不开始担心其他的拉请求自动化主题，就像我们将在下一节中讨论的那些。

谈了很多理论。但是，让我们实际一点，只是为了完善我们对这些 DevOps 概念如何工作的理解。让我们看一下为一个实际的存储库设置 ci 是什么样子的。

托雷

这是实时聊天的例子。这是 slack 的开源版本。整个第三层用作演示库的是内部文档。比方说，对于 slack 的开源版本，我们希望每次开发人员提出更改时都运行测试，这样在 pull requests 选项卡中，我们就能够知道某个更改是否是好的。特别是，让我们说一个开发者正在改变网站的颜色。

在主网站中，登录后

侧边栏顶部的栏是紫色的，可能客户要求颜色是蓝色的。相反，

如果我们让我们团队中的一个开发人员来做这个改变，他们会去找必要的设计文件

并编辑颜色。

在这种情况下，有两种颜色要改变。

如果开发人员打开了这个拉请求，我们就很难检查他们的更改。

如果没有 CI 系统，我们只能看到文件更改和提交描述。所以我们可以看到他们编辑了主点 CSS，并且改变了这些颜色值。但是很难理解这件事的后果。尤其难以理解的是，这是否会对现有用户产生负面影响，尤其是那些不仅仅是改变一种颜色的改变。

对于这个请求，如果我被要求检查它，我将不得不把这些更改拉到我的本地开发机器上，在本地运行脚本，然后在本地评估这些更改。或者，我可以要求开发人员建立一个屏幕共享会话，他们可以指导我完成更改。这两者都给开发过程增加了很多摩擦。如果我可以完全通过网络界面评估他们的改变而不需要任何参与，那就更好了。

但是持续集成是有帮助的。持续集成允许开发人员建立全面的测试，这样，如果某样东西不再工作，在提议的更改之后，它会在拉请求中说正确。

现在让我们关闭这个变更，并查看存储库以了解如何设置 ci。

还有这个仓库。其中一项服务叫做 Cypress。这是一种端到端的测试服务。

它包含几种配置。这些配置通过一个假的浏览器与页面交互。

例如，该测试输入用户名和密码，然后登录，然后确保用户确实被锁定

该测试进入消息区域，输入一条随机消息，并确保该消息实际上已经提交，可以在剩余的聊天区域中查看。

通过足够多的端到端测试，您有理由相信像这样的聊天系统

继续工作。

因此，我们希望每次开发人员提出更改时都运行这些测试。要做到这一点，我们必须在 GitHub 中安装一个插件，设置服务器在每个 pull 请求后运行，并在新服务器上运行这个测试。

为此，让我们在这里设置层。

对于我们的用例，很容易直接安装到我们的 GitHub 帐户上。

我们现在可以将它安装到我们的 GitHub 存储库中。

现在，它被列在这里。这意味着我们已经成功地将蕾拉配置项安装到此存储库中。

然而，什么也不会发生。因为没有配置文件，我们需要为这个存储库设置一个配置文件，它将启动整个堆栈，然后根据需要在 Cypress 中运行测试。

让我们现在做那件事。因为我们的存储库是基于 Docker compose 的。让我们使用 Docker compose 示例作为起点。

在这里，我们将安装 Docker，这是一种容器化技术。在后面的系列讲座中，我们将更多地讨论容器和虚拟机。安装 Docker compose，这也是同时运行多个容器的一种方式，这些概念将在后面的演讲中变得清晰。

我们将存储库文件复制到测试运行程序中。

我们构建所有的服务，启动所有的服务，然后部署管道。

让我们跳过空白部分，我们将在本 DevOps 课程的部署部分讨论这一点。

所有服务启动后，让我们运行测试。

幸运的是，我已经为此预先设置了一个脚本，所以我可以复制我的配置。

概括一下，这种配置的作用是

安装必要的软件，这种情况下，Docker 和 Docker compose，

复制存储库文件，构建所有的微服务，在测试运行器中本地启动它们，然后针对它们运行我们的测试。

现在，我们已经将 ci 层安装到我们的存储库中，我们所要做的就是添加这个配置，我们已经为它设置了 ci。

所以让我们点击添加文件，

我们将它命名为层文件。这就是 C 层配置文件的方式，当然，其他 ci 提供程序会有不同的文件名，

我们将复制我们的配置。

我们将提交该文件。

现在我们已经设置了 ci，我们可以看到提交名称旁边有一个点。

当测试通过时，这个点会变成一个勾号。这意味着每次开发人员推出新代码和我们的源代码管理工具时，都要查看一个成功指标。也就是说，无论测试是否自动通过，他们都不需要自己运行测试。并且评审者不必相信最初的开发人员已经实际测试了变更的有效性。

因此，让我们回到我们最初提议的将生产中的颜色从蓝色改为紫色。

在这里，我们将进行更改并重新打开拉请求。但是因为我们已经为它配置了一个 CI 提供者，我们将能够看到测试直接在 pull request 视图中自动运行。

现在，当我们的开发人员要求我们进行审查时，我们就可以更容易地判断变更是否对我们的客户工作流产生了负面影响。特别是，因为我们已经配置了 Cypress 和后来的 ci 来检查登录和发布消息是否仍然工作。我们知道，对于这种变化，即使许多文件可能已经被改变，核心工作流仍然工作，这给了我们一定程度的信心，代码没有发生任何可怕的事情。

因此，我们可以通过查看文件更改来初步了解开发人员所做的工作。

然后我们可以查看 CI 正在做什么。所以如果我们打开相关的管道，

我们将看到测试正在运行，应用程序的新版本已经在 CI runner 中构建并启动。测试正在一个接一个地进行。在这里，经过测试，您可以在我们的替代 slacks 聊天页面中发布聊天消息，登录页面加载，登录工作正常。

现在，在我们的“pull request”视图中，我们可以看到一个大勾号，表示所有相关的配置项检查都已通过。然后，您甚至可以在 GitHub 或其他源代码管理平台中自动化某些必须完全通过的检查。因此，您可以自动执行在合并变更之前必须通过的所有 ci 检查。让我们确保开发人员永远不会审查那些明显有问题的代码，这样会破坏您的测试。在这里，您不仅需要运行端到端的测试。你也可以运行 linters 单元测试和其他版本的测试，我们在这一系列的演讲中都提到过。现在，我对更改感到满意，我已经查看了文件，并且我看到 CI 已经通过，我可以更有信心地合并它，而不是在没有自动化的情况下。

这就是设置 ci 和应用设置的全部内容。让我们稍微回到理论上来。

继续测试和持续集成的话题，让我们来谈谈代码覆盖率。所以代码覆盖率定量地衡量了有多全面

对代码库的测试是，你可能认为你有足够的测试来发现所有常见的错误，并真正检查你的应用程序的所有功能。但很难确定具体数字。除非你在测量代码覆盖率。这是一个流行工具的代码覆盖率图。每个方块代表一个文件，颜色代表覆盖该文件的测试数量。所以亮绿色意味着 100%的文件被测试。亮红色表示没有测试任何文件。因此，这将是应该被测试或从测量中排除的文件的优先级。

假设您正在接管一个现有的代码库，它相对较大，有 100，000 行代码。

这些年来，它已经被 100 多个用户采用，你应该在不伤害这些用户的情况下维护它并添加特性。所以你首先要看的是单元测试，我们之前讨论过。但是他们并没有被之前的维护者优先考虑。所以库和命名约定不匹配。很难区分哪些测试正在测试哪些文件，哪些文件需要测试。在您编写任何新特性之前，您希望有一种客观的方法来衡量代码库的某些部分对更改的敏感程度。如果某个东西有非常全面的测试，那么与代码中没有害虫的部分相比，你就不会害怕修改和添加触及该部分代码的特性。所以这是代码覆盖率真正闪光的地方。你有一个复杂的代码库，它有现有的用户，你想强制执行测试的编写，这样事情就不会以一种客观的方式中断。所以进入整个系列的第一段代码，让我们看看这个 JavaScript 函数，我会把它放大。

所以这是一个非常简单的函数，如果不是有点做作的话。

它需要一个数字。

它定义了一些变量。它循环到那个数字，将字符串推入结果列表。

然后每隔 50 个元素，它将一个特殊的字符串推入结果列表。

所以这个函数只有 10 行代码。但并不是所有的 10 行都是相等的。所以实际上，像这样的程序中有三种代码行。有语法行，像这些结束行，实际上没有任何代码。为了程序员的利益，它们只是简单的语法构造。你知道，测试这些是没有意义的，因为你如何测试分号是否存在？

有像这样的逻辑线，实际上有副作用。所谓副作用，我的意思是，如果你移除这些线，会改变程序的行为。

像这样的支线改变了程序的流程。所以 for 循环，以及在编程中使用的 if 语句，作为改变命令运行顺序的结构，所以这个 if 语句，如果计算结果为 true，就会运行这行。如果它的计算结果不为真，它就不会运行这行代码。所以重申一下，三种行都是语法上不做任何事的。有影响的实际逻辑，以及改变执行哪行代码的分支逻辑。

代码覆盖率通常被定义为行覆盖率。所以它是测试执行的非语法行，占非语法行总数的比率。

再次考虑这个测试。

如果您希望函数应该与的输入一起工作，并且手动计算函数应该为的输入返回什么

这将是对您的函数的单元测试。但是因为您只在 if 语句的输入上执行它，而 if 语句需要至少 50 的输入才能执行，所以不会运行。所以你要测试这一行，它会执行这一行，它会执行这一行，这一行也会执行，所以你会执行

六行中的五行，

这将是 83%的测试覆盖率。所以仅仅这个测试就能让我们大部分了解我们的功能和它的问题。

相关的概念叫做分支覆盖。因此，在我们上面的例子中，它不是测量有多少行代码，而是测量一组行，只有两个分支。有主分支。这是 for 循环的主体，实际上还有第三个分支，叫做 if 语句主体。所以这一行总是执行 for 循环的主体。

只有当 I 小于 n 时才会执行，所以这里你需要 and 大于或等于 1，否则这几行要执行。而这一行只有在 I 大于等于 49 的情况下才会执行。

所以分支覆盖率就是这三个分支中有多少个分支被测试评估为真。所以你想知道有多少分支被测试了。这很有用，因为如果这一行代码执行了，那么这一行代码就会一直执行。因此，将它们都视为需要测试的独立事物，实际上并不意味着将这些语句的主体视为需要测试的事物。

如果你用分支覆盖率来度量测试，你会看到三个分支中的两个或者 x 在测试中被评估。

那么在分支覆盖率中，什么时候你应该关心这个行覆盖率，我们已经讨论了一个场景，其中你继承了一个现有的代码库。然而，它在许多不同的情况下都很重要。通常，您应该测量并优化代码覆盖率。如果下列任一项为真。你的产品有用户。如果这些用户受到 bug 的影响，他们可能会离开，在这种情况下，度量代码覆盖率是很重要的，因为它让您与您的团队一起改进代码覆盖率并减少 bug 的数量。你和不太值得信任的开发人员一起工作，比如承包商或保险公司，你把他们带进你的代码库，他们需要在固定的时间范围内做出改变，比如实习。因此他们可以立即成为整个代码库的专家。你希望他们能够做出改变，而不必太担心事情会变糟。

或者，如果你正在处理一个非常大的代码库，许多单独可测试的组件。您的代码覆盖分析可以补充测试驱动开发，这是我们在之前的谈话中谈到的，以确保团队中的每个人通常都在做重要的事情，并且他们所做的事情不会在未来中断。

因此，在产品拥有足够多的用户之前，让事情变得过于死板是代码审查自动化中的一个常见错误，如果你强迫开发人员获得 100%的分支覆盖率，那么为每个功能编写两到五个单元测试，这将使他们在开发用户实际上会注意到的功能时慢得多。请记住，用户永远不会查看测试。所以用户唯一关心的就是系统的稳定性。因此，如果你有一个 MVP，或者如果你有一个没有很多活跃用户的产品，它可能不值得衡量或优化分支覆盖。直到那些用户非常关心稳定性。

通过编写单元测试和其他类型的测试，要记住的一件重要事情是，开发人员正在巩固他们可能不得不放弃的功能的实现。如果你开发了一个特性，但它最终并不是你的用户真正想要的，抛弃这个特性，然后长期开发它总是一个更好的主意。因此，如果开发人员构建了一个特性，并为其编写了许多测试来提高该特性的代码覆盖率，他们将更有可能不丢弃它，因为他们会有一种主人翁感。可以说，他们会对构建这个功能并使其变得更好有一种沉没成本的感觉。因此，重要的是不要过度优化这些事情，它们很重要。而且是主观想法。但是实际上，当你的用户开始抱怨稳定性时，你会注意到的。

所以从组织上来说，有一些与代码覆盖率相关的公共政策。

当您继承一个代码库时，第一种方法很有用。政策是代码覆盖率不能降低。这是最容易自动化的一个。正如我提到的，如果您正在接管一个现有的代码库，这将特别有用。这个想法就是代码覆盖率永远不应该降低。如果当前代码已经测试了 75%的代码行，而您的新变更引入了 40 行代码，那么至少需要测试其中的 30 行。否则，您的更改，代码覆盖率将会低于 75%。你会降低平均代码覆盖率。

与大多数代码覆盖策略一样，这将增加稳定性，因此会有更少的错误，因为以开发人员的速度为代价，事情会得到更好的测试。因此，开发人员将不得不进行一些复杂的测试，他们可能会花很多时间来构建测试基础设施。因此，如果你制定了这种政策，特性的发布速度将会变慢。如果你用代码审查自动化来执行它。

这一政策的不幸副作用是，开发人员不太可能对更难测试的变更(如集成)进行工作。因此，开发人员受到他们的薪水和他们的经理的激励，快速发布特性，在每个 Scrum 周期中开发许多特性。因此，如果某些功能更难测试，因为它们需要互联网连接或连接的第三方 API，这些功能将更难制作和测试。因此开发者将会

不管它们对用户是否重要，都不太可能去做。因此，对于第三方集成之类的事情，有一个适当的豁免政策可能是有用的。如果您的组织决定采用这种代码覆盖率不能降低政策。

另一个有用的策略是测试文件的代码所有者。如果您已经使用代码覆盖自动化来保持代码得到良好的测试，那么为测试本身定义代码所有者通常是有益的。这意味着开发人员可以在没有正式审查人员的情况下更改实现细节。但是逻辑变了。因此，测试定义了成功对于一个函数或一个算法意味着什么，然后，为一个新的实现改变测试需要得到高级开发人员或经理的批准。

在 GitHub 中，对于一个工程经理，GitHub 代码所有者文件可能包含这个，这意味着 spec . j . s 是一个常见的 JavaScript 测试和命名约定。在工程经理处，用户名意味着，如果有一个名为 code owners 的文件，其中包含该文件，那么工程经理将需要批准任何更改，这将更改测试，这可能是一个好政策。

因此，如果您正在使用测试驱动开发的大型代码库工作，尤其是，

或者，如果您正在雇用实习生，或者承包商，或者如果您的用户对 bug 特别敏感，并且您担心他们会有不好的体验，如果即使是很小的 bug 也能找到他们，那么安装一个代码覆盖度量工具可能对您的团队最有利。在撰写本文时，这是开源世界代码覆盖、工作服和代码环境中最常见的三种。

我们已经讨论了测试，也讨论了持续集成。这些真的很像 DevOps 代码评审自动化管道中设置的初始事物。但问题是，它需要开发人员的参与。当然，开发人员可能正忙于构建特性，不一定想要进行测试或提高测试覆盖率。所以让我们来谈谈林挺，这是一种近似测试的东西，但不需要开发人员花费任何时间。

linters 是查看程序源代码并自动发现问题的程序。它们是拉式请求自动化的一个常见特性，因为它们确保了明显的错误不会进入生产，这在这里是显而易见的。举个林挺的例子。我们再来看一个 JavaScript 程序，非常简单的一个，就算不懂 JavaScript 也要懂，

它定义了一个变量 var x 等于 5，定义了一个函数但在开括号后继续，这通常被认为是不好的做法。它使用 let 作为第二个变量，并用与第一个变量相同的名称定义它。所以这只是令人困惑，你知道，不会被称为好代码，代码审查者会在代码审查中提到这一点。

然后它说当 x 小于 100 时，console，log x，然后它关闭了这一行的 while 循环，并且弄乱了 end Det。为了保持一致性，这三行应该缩进，然后关闭函数。最后，你应该意识到这个 while 循环永远不会结束。在 while 循环体中，x 不递增。因此，仅仅通过在不运行任何环境的情况下静态地查看代码，或者甚至用浏览器查看代码，就可以知道这个循环将永远运行下去，而这可能是一个程序员不希望看到的。

因此

这种反馈的大部分可以自动化，一套规则，如不要隐藏变量。永远不要在内部作用域中命名一个与外部作用域中的变量同名的变量。外部作用域中的变量可以应用于每个提议的更改，这样人类评审者就不必浪费精力留下代码风格的注释。维护和运行这种列表的工具称为 linters。

相关地，另一类代码评审反馈与代码风格有关。编码局很容易浪费时间指出风格选择，如制表符与空格，或骆驼案与坑洞案。这些讨论不会给最终用户带来任何价值，你知道，你的客户并不关心你的代码是用什么大小写的。最终，它们只会引起工程团队的不满和错过最后期限。如果因为这样的评论，一个评审需要额外的几个小时，这几个小时程序员可以把他们的注意力集中在另一个特性上。

所以工程组织最终应该采用全球风格指南。

但是在大多数情况下，从类似谷歌风格指南的东西开始，这是一个很好的起点，谷歌风格指南是开源的，可以通过这个链接获得。

这些指南通常带有棉绒配置，这有助于一切

保持风格相似，一些编程语言如 Python 和 go 都有自己的风格指南和自动化，如 Pep eight。对于 Python 来说，这将使使用这些编程语言的开发人员更容易保持统一的风格。

你可以为代码风格做的一件有组织的事情是编织，或者代表吹毛求疵。如果有代码风格的评审反馈，而不是在代码评审阶段阻止，那么对于代码评审人员来说，留下称为 mitts 的小型评审注释可能更好。所以他们会说针织全结肠不应该这样设计。

这太棒了。因为它允许评审者将一些东西和一些反馈合并在一起，这样我们就不必花费在一小段重构上，这些重构可以在以后的某个时间点完成。

一旦采用了样式指南，就有可能配置工具来自动格式化代码以遵循样式指南，这些工具被称为自动格式化器。以及我们在 ci 层使用的编程语言 go，下面这样的命令将使用标准格式，它是 go 附带的，用于清理存储库中的所有源文件。因此，我们将使用 Janu，find 命令，查找具有 go 扩展名的文件，并对它们执行 go 格式。这将获取所有的源文件，然后用它们的样式指南对它们进行格式化，以便它们都通过样式指南。

当然，如果您的 ci 系统自动运行测试，那么每次您的代码被推送时，代码也会被自动限制。程序员不应该等着人类评审员告诉他们代码是否有限制和风格是否恰当。在大多数情况下，用 CI 系统自动运行林挺和格式化既便宜又方便。

因此，一个简单的解决办法是你得到另一个勾号。为了快速设置，让 lint 像在 ci 中运行单元测试一样运行是一个好的开始，所以如果代码没有正确列出，添加一个 x，然后开发人员可以非常快速地获得风格反馈，而不需要与其他人交谈或浪费他们的评审人员的时间来获得这种反馈。

配置项配置可能如下所示。所以复制项目文件，运行林挺脚本。然后，如果林挺脚本失败，整个管道将失败。这种方法阻止了评审员选择风格，它传递了 linter 是对过分热心的代码评审员的完全合理的反应。因此，即使像这样简单的自动化也可以提高整个开发团队的开发速度。它还完全避免了评审人员必须给出风格反馈，在所有代码评审通过的检查中，就像它通过了所有提交的风格好吧，评审人员可能仍然会留下一些反馈供将来参考，但他们不应该因为甚至在 linter 中没有的小风格选择而阻止提交进入生产。

一个更好的长期解决方案是设置一个提交返回按钮，这是一个普遍的想法，并且代码审查自动化随处可见。但是在这个具体的例子中，它可能是这样的。所以你会说如果代码没有限制，

是的，运行带有破折号修正标志的 lint，它再次检查所有的源文件。是的，lint 就是 JavaScript 的 linter。所以这会遍历所有的源文件。对他们中的每一个人，都将适用林挺

规则，它将修复任何文体错误。然后它会创建一个提交

除了开发人员提议的之外，还有一组额外的文件更改。它将创建一个新的分支，并列出一个后缀。它会推向那根树枝。因此，开发人员可以推送无限的代码，机器人会自动创建一个提交来提升所有内容，并创建一个新的分支，这样，如果开发人员的代码被认为是好的，审查人员可以简单地合并 Linton 分支，而不是开发人员的原始分支。然后我们用 lint 破坏了管道。这意味着无限版本不能合并。但是有限的，假设所有没有列出的反馈都是相关的，

可以合并。所以我们有两个分支，一个是开发人员提议的，另一个是有限的，代码审查人员会查看没有租用的。他们会说这是好是坏，比如提交的逻辑是好的。如果它是好的，那么 GitHub 中的评审者可以合并这个分支，而不是他们被要求评审的分支。该分支将与原始分支相同，在其顶部有一个额外的提交。

许多编程语言都有一些限制器的例子。2021 年的标准是 Eastlands。打字稿。现在也用 Eastlands，Python 你

皮兰德和弗雷克八号。c++就主观多了。但是一个常见的选择是上面提到的 Google 风格指南中的 Google CPP lens，go 带有一种叫做 go format 的格式，它的行为有点像 linter。尽管除此之外还有额外的规则库可用，Java 有 checkstyle 和 find bugs，可能还有更老的选项，但是像 Java 这样的语言有很多选择。Ruby 已经破解了 rubocop 和 pronto。我们已经看到用户普遍使用

Java、JavaScript C sharp 和许多其他语言都可以用 sonar cube 来提升，sonar cube 是一个流行的静态分析框架，通常在大型企业中使用。但是它有一个开源版本，对于 10 个想要建立静态分析的开发团队来说，这是一个很好的起点。

最后，我们采访了一家名为 Deep source 的初创公司

启动到启动。他们也在用静态分析做各种有趣的事情。静态分析只是查看源代码而不运行它并找出错误的实践。所以我鼓励你也看看深层来源。

因此，与大多数其他代码自动化工具相比，linters 非常容易安装。任何有一个以上开发人员的团队都应该立即建立一个 linter。捕捉像无限循环这样明显的错误。只要看一下代码，linter 就能告诉你是否有一个常见的编程错误，比如无限循环。

自动林挺标配有许多代码编辑器。因此，明智的做法是教开发人员如何配置他们的代码编辑器，以使用您的团队在 CI 自动化中设置的现有林挺规则，这样开发人员就不必等待推送他们的代码来获得反馈，他们可以直接在他们的编辑器中获得黄色曲线。

然后是开发早期产品的团队。导师可以帮助避免编写单元测试。

除了依赖测试套件，您还可以经常依赖静态分析来查找常见的错误，比如代码根本无法编译或者

无限循环或风格问题。这有助于小团队让他们的产品得到许多用户的反馈，而不需要用测试来锁定事情。

没错。这就是林挺和代码风格。我们将在下一个视频中看到。

让我们通过谈论短暂的环境来结束我们对代码审查自动化的讨论，当谈到进行代码审查和帮助开发人员合并他们的变更时，这确实是最新和最好的。

短暂环境是包含整个应用程序的自包含版本的临时环境。一般来说，对于每个特性分支，它们通常由 slack bot 启动，或者在每次提交时使用 DevOps 平台(如后来的 ci 本身或 Heroku)自动启动。

临时环境正在取代传统的 ci 平台，成为最有价值的 DevOps 代码评审体验。因为这些环境是在所有利益相关者，不仅仅是开发人员，而是产品的每一个变更上建立的，所以设计人员可以审查变更，而不需要建立开发人员环境或者要求与提出变更的开发人员进行屏幕共享。

举一个更具体的例子，假设开发者正在改变网站上的一些东西。所以他们在改变，你知道，前端或后端，或者，你知道，网站的某些组成部分。他们希望获得对提议的变更的反馈。所以一个代码评审员会看着代码，他们可能不理解这种变化的视觉影响是什么。但是在股骨环境中，在代码评审视图本身中，评审者只需要点击那里的按钮。

我来放大。所以在 GitHub 中，这是评论者会看到的。他们会看到描述、代码更改，还会看到一个查看短暂环境的按钮。当他们点击这个按钮时，它会唤醒一个版本的网站，其中特别包含了这个提议的更改，这样审阅者就可以实际查看这些更改在视觉上和工作流程上是否有效。

一般来说，短暂的环境介于开发环境和阶段环境之间。在极端情况下，分级完全被称为连续分级的正式环境所取代。

短暂环境的好处。嗯，采用短暂环境工作流最常见的原因是它加速了软件开发生命周期。开发人员可以直观地查看变更的结果，而不需要专门对代码变更本身给出反馈。此外，开发人员可以与非技术合作者(如设计人员)共享他们的工作，轻松确保链接到提议的版本。

因此

你可以发布一个类似这样的松散消息，你可以访问这个链接并给我反馈，而不是需要设置一个缩放呼叫来共享你的屏幕，以让其他人看到你提议的更改。

建立短暂环境最困难的部分是处理状态。所以处理像数据库和微服务这样的事情，

从本质上来说，你知道，短暂的环境是暂时的。它们与生产环境相隔离，实际上只持续一个拉请求的时间。审阅者应该能够删除审阅中的资源。因此，他们应该能够看到，如果您知道，删除用户仍然有效，而不用担心会影响生产环境。因此，在短暂环境的早期实现中，将具有只读权限的 API 服务器连接到临时数据库可能是有意义的。因此，如果您使用 AWS，您可能有一个对数据库具有只读访问权限的 Iam 角色。但是在这种情况下，你将无法注册该服务，例如，因为这将需要数据库权限。最终目标应该是每次提交都有一个新的数据库副本。因此，每次开发人员提出更改，他们都会获得专门针对其环境的新数据库，这样他们就可以随心所欲了

理想的临时数据库有三个属性。它是预先填充的，因此包含有代表性的匿名数据。在 PII 过去的安全审计中，个人身份信息必须从短暂环境中使用的数据库中清除。应该是可以撤销的。所以如果在审查过程中数据被删除，应该很容易将数据库重置为其原始状态。这对于阅读破坏性的端到端测试也是至关重要的，我们将在后面讨论。并且它应该被迁移，数据库应该使用当前在生产中使用的模式，知道一些东西是否正在使用旧版本的模式是没有多大用处的。正式环境或中断或性能不佳的数据库迁移暴露的最常见问题之一。

对于短暂的环境，另一个难以解决的问题是生命周期。那么你什么时候创造它们，什么时候毁灭它们呢？经典的方法是将拉请求的生命周期命名为短暂环境的生命周期。因此，如果开发人员打开一个拉取请求，为他们创建一个环境，保持它 24 小时运行。直到开发者删除环境。

要考虑的最大因素是成本。如果每个 FML 环境的成本是生产成本的 10%。因此，它便宜 10%,并且您有 30 个开放拉取请求，您将使您的月成本翻两番。所以你知道，这是一个昂贵的开发工具。

另一种方法是创建一个聊天操作机器人，允许在特定的超时时间内为特定的分支创建新的环境。例如，在 GitHub 问题描述中创建的用户类型 slash PR bot 可以创建一个环境，或者在 Slack 中，用户可以做同样的事情。

这要求在需要时调配环境，这可能会很慢。同样，很难判断何时删除这些内容。最好的方法是为每一个变化创造一个短暂的环境。这与 PR 工作流非常相似，但是在它们被提供时，将它们休眠。

只有少数供应商能做到这一点。一个是 Heroku，它可以通过 Heroku review 应用程序打开和关闭环境。而另一个是层 ci，不要脸的塞，我猜。

所以当用户使用环境和 ci 层时，混合忍者是不够的。您可以使用内存快照来自动完成这项工作，但这有点复杂。因此，这可能是最好让第三方来做的事情。

回到连续分段的概念。

想法是将临时环境和 CI 管道合并在一起。这是 ci 本身主要向我们的用户销售的一个层次。随着您的短暂环境变得更加强大和易于创建。它们接近并超越了传统持续集成管道的许多方面。因此，如果你能建立网站，后端和数据库，那么运行测试就相对容易，因为测试通常更容易包装它们的整个后端。从逻辑上来说，这个概念变成了连续阶段，ci CD 和短暂的环境形成了一个 ci CD 流，在这个流中，一个基础设置了所有的需求。然后，这又分支到单元测试，还有服务器，还有评审环境，还有 linter，一切都来自那个公共基础。

如果你打算自己做，你可能需要一个月的预算，或者花一个月的时间来设置你的环境。因此，如果您的生产环境有许多不同的微服务和许多不同的数据库，那么建立一个短暂的环境流将会相对困难。像脸书这样的大公司已经为他们的内部拉动式需求设置了这个。

但是他们没有雇佣开发团队，基础设施软件工程师来做这些。因此，如果你是一个较小的公司，你可能会再次坚持使用托管服务，如层 ci，而不是在你有大约 20 名开发人员时自己开发。

为了避免启动和停止环境的微观管理，最简单的方法是使用托管提供商。如果你只是做前端开发。一些流行的选择是细胞网络。但是，如果您正在进行全栈部署，目前唯一可用的选择就是层 ci 本身和 Heroku review 应用程序。在许多源代码平台中都有一些选项，比如 Git lab 有一个环境特性。但这并不是真正短暂的环境特征。所以你应该探索所有这些选择，做出明智的决定。

这就是短暂的环境。这就结束了我们对代码审查自动化的讨论。

因为拉请求自动化是 DevOps 工程的核心部分，所以我们在这里再做一个应用教程。

在这个例子中，为了简单起见，我们将按照我们在使用托管平台之前讨论过的相同方式来设置一个股骨环境。

因为我们已经为此存储库设置了配置项，所以我们已经有了我们的层文件，这是我们的配置项配置。但是，许多 ci 提供者(包括 layer ci、Roku 和其他提供者)可以设置临时环境，这是一些小的生产部署，您可以作为评审者使用它们来实时评估变更。同样，假设我们这次将颜色从蓝色变回紫色。我们希望有人能够有效地审查我们的变化，不仅通过查看测试结果，而且通过查看联邦环境。阅读手册问答，你可能会看到，在这种情况下，它实际上很容易设置。去我们网微服务吧。

让我们创建一个新文件。

这里，我们将创建另一个层文件，以便它们并行运行。我们会说从我们的基础层文件，

我们会说暴露网站。

我们将公开运行在跑步者内部的网站。后来 ci 有了这个 expose website 指令，但是许多其他提供商也有类似的功能，您可以设置。

让我们直接为它创建一个拉取请求。

因此，在这里，我们的代码审查员不仅会看到测试结果，正如你所看到的，这些都在这里，初始层文件。

让我们看看实际的图表，以便更好地理解发生了什么。这里，我们在主层文件中运行我们的测试。

主层文件再次构建了所有的服务，启动了所有的服务。现在，它正在运行我们的 Cypress 测试，就像在 CI 章节中一样。

但是在 Cypress 测试运行之后，我们将有第二个环境，它继承了第一个环境，第二个环境将有一个可点击的链接，可以用于手动 QA。

让我们看看这里。

测试的快照已经完成，这意味着暂时的环境可以开始构建了。

现在，您可以看到它构建了一个“临时服务器”按钮，您可以在这里连接到它。

因此，在我们实际的拉取请求中，现在所有的测试和 ci 服务都已通过，

我们可以单击股骨环境按钮。

一出现。

我们可以单击主层文件详细信息，

我们可以点击服务网络短暂环境，

我们可以点击查看网站。这样做的目的是唤醒我们最初为运行测试而设置的管道。但是它会将互联网可见链接转发到内部的 web 服务器。这里我们专门为这个测试创建了一个全新的环境，我们可以看到测试已经运行并发送了消息。

我们可以评估这种变化，这样我们就可以测试创建通道是否有效。

在测试通道中，仍然可以设置消息。

这意味着你不需要 100%的测试覆盖率来理解一个渠道的细微差别

对于每个拉取请求，您将能够自动启动一个新的环境，然后在需要完成审查时唤醒该环境。

既然我们对环境工作正常感到满意，我们就可以合并拉请求了。

从现在开始，编辑网站的所有更改都可以手动管理，所以审查者可以检查事情是否正常，而且 QA 团队或设计师或产品经理也可以检查更改是否确实改变了它应该做的事情。正式环境就是这样。让我们回到理论上来。

欢迎来到 DevOps 学院部署。这一次，我们将讨论基础概念。首先，当您谈到部署时，您指的是虚拟机。你说的是集装箱。集装箱通常也被称为码头工人。所以我们来说说这两者的区别。在我们讨论部署任何东西之前。

人们谈论 DevOps 部署时，他们通常会谈到 Linux，所有部署中的很大一部分都是针对 Linux 服务器的。容器实际上只在 Linux 中定义，在目前的生产中。

所以记住所有这些，让我们抽象地谈谈 Linux。所以 Linux 真正帮你做的是，当你写程序时，照顾四件事，它照顾内存。所以程序需要内存来做事情，内存也被称为 Ram。由于你只有有限的内存，Linux 本身需要计算出哪些程序将获得哪些内存区域，因此哪些内存块将运行哪些程序。

Linux 也照顾处理器。因此，如果你并行运行两个东西，Linux 将确保两者都有适当数量的处理器。

如果你曾经在笔记本电脑上运行计算密集型任务，你可能会注意到你的浏览器变慢了。这是因为它没有获得足够的处理器时间。因此，如果您正在运行生产工作负载，Linux 需要确保每个程序都获得公平的处理器时间份额来运行实际的程序。

因为是磁盘，所以 Linux 获取所有程序的文件并在磁盘上为它们分配空间，你可能有多个磁盘，你可能有旋转磁盘和固态驱动器，你甚至可能有跨网络共享的磁盘。所以 Linux 负责所有这些，并确保正确的文件在正确的磁盘上，并且程序可以访问这些文件。

最后，还有设备。因此，除了磁盘内存和 CPU 之外，还有 GPU 之类的东西。所以对于机器学习，你经常会看到 GPU，以及网卡之类的东西，你用它们来连接互联网。

Linux 需要获取这些单独的资源，并将它们分配给进程。因此，如果你有五个进程试图同时连接到互联网，但只有一个网卡，Linux 需要确保正确的消息被发送到正确的上游网站。并且响应被发送到下游的正确程序。

在图表中，这就是它的样子。这里我们有三个程序，Chrome、Notepad 和 Spotify。它们都运行在 Linux 上。所以这是假设你有一个运行这三个程序的 Linux 服务器。

这里有四种共享资源。所以 Chrome，要求 CPU，Linux 会分配一部分 CPU 时间给 Chrome。它还会分配一些记事本和一些给 Spotify。对于所有其他共享资源也是如此。

这很好，但是分享太多了。我的意思是程序知道彼此。因此，如果您有一个程序，它在家里接收一个名为 file . txt 的文件，那么它可以创建该文件，但另一个程序可以删除或读取该文件。所以文件可以跨程序读取。这意味着这些程序可以相互通信，而这并不总是你想要的。

例如，程序员经常使用不同版本的 Python。Python 是一种流行的编程语言。有两种流行的版本。一个是 Python 2，一个是 Python 3，但都叫 Python。因此，如果用户 bin Python 中的文件是 Python 2 的可执行文件，而你试图用它运行 Python 3 的程序，那么这个程序就会出错，因为你使用了错误的 Python 版本来运行它。然而，有些程序可能需要 Python 2，有些程序可能需要 Python 3。所以在这里，程序之间有串扰，因为它们都在读取用户 bin Python，但是它们期望那里有不同的文件。这就是我说的程序有时会过度共享的意思

他们在同一个地方需要不同版本的文件。所以你不能同时运行两个程序。

类似地，两个 web 服务器可能监听端口 80。这就是网站如何让你连接到他们。因此，如果您运行两个 web 服务器，并且都希望端口 80 打开，那么第一个服务器将正确启动。第二个会崩溃，说端口 80 已经被使用。这种共享资源的问题是虚拟机和容器真正的亮点。它们允许你在程序之间分离像文件和端口这样的资源，这样程序就不会互相踩对方的脚。

所以在这里，如果你在那个容器中运行你的三个程序，它看起来会非常相似。所以 Chrome 会运行，但它会在一个容器中运行。该容器将与 Linux 对话，然后由 Linux 分配容器资源。其他程序也是如此。

现在，这可能还没有意义。但是让我们来讨论一下，当你把东西放进这样的容器时，实际上会发生什么。那么当程序和 Linux 之间有一个容器时会发生什么呢？

最大的变化是每个程序将获得自己版本的共享资源，如文件和网络端口。

运行 chrome 的容器可能会在 tilby slash chrome slash cash 创建一个文件。虽然运行 notepad 的容器可以读取该文件并发现它不存在，但它们会获得所有系统文件的不同副本，因此它们无法相互交流，或者拥有冲突的 Python 版本。

类似地，如果您有两个运行的 web 服务器，两个都希望能够打开端口 81，将能够在其容器中打开端口 80，而另一个将能够在其容器中打开端口 80。所以你可以让两个程序都认为只有一个程序在监听端口 80。但实际上，它们会被隔离在自己的容器里。

因此，在 Linux 中，容器通过创建名称空间来工作，名称空间是 Linux 的一个特性，它将共享资源组合在一起。如果在 Docker 容器中有五个进程一起运行，它们仍然会在 Linux 本身中运行。但是他们看不到其他的进程，那些在 Linux 主机上的进程。因此，在容器内，如果你运行 PS，au x，并计算有多少行输出 VSD UX 是你在 Linux 机器上看到的运行命令，你可能会看到 10。这意味着容器中有 10 个可见的进程。但是在 Linux 中，在这个容器中，如果你说有多少个进程在运行，它会说有 10 个进程。但是在 Linux 内部，您会看到数百个进程正在运行，包括这个容器中的 10 个进程。因此，容器就像沙箱或命名空间一样，放在一组进程中，进程看不到容器外的文件，也看不到容器外的进程或网络端口。他们只能看到这个容器中的端口。

所以本质上，正在发生的是程序在问，用户 lib Python 的内容是什么，在我们之前的例子中，Linux 没有如实回答，而是用另一个文件的内容来回答。因此，容器说明什么是用户库 Python，然后 Docker，如果您为您的容器使用 Docker，将使用此文件的内容 var lib，Docker overlay Fs one user lib Python，这是全局系统中完全独立的文件。所以每个容器都有自己的文件视图。

这个小骗局允许程序并行运行，因为 Linux 将会为每个容器响应不同的文件。一个容器可以让 Python 指向 Python 2 的可执行文件，一个容器可以让 Python 指向 Python 3 的可执行文件。

如果容器是这样工作的，那么虚拟机是怎样工作的，它们有什么不同？

嗯，虚拟机非常类似于模拟器。如果你曾经见过有人在现代电脑上运行旧的视频游戏，他们使用的是虚拟机。

所以容器的想法是提供假的 Linux。

在容器内，他们并不真正知道他们在容器内运行。他们可以看到文件，但是文件只是指向真正的 Linux 安装中的不同位置。虚拟机的想法是生产一个低一级的假版本。所以漂亮的生产假版本的 CPU，内存磁盘和设备。

Docker 的虚拟机等价物称为管理程序。它是负责创建虚拟机的程序。因此，当一个虚拟机正在运行某个东西时，它对应于 Linux 中的一个虚拟机管理程序实例。

虚拟机管理程序可能会对虚拟机撒谎，说连接了一个 SSD。有一个驱动器连接，然后有 50 千兆字节的容量。但是，当虚拟机写入该驱动器时，它会转到文件，而不是真正的驱动器。然后在主机上，可能是

这个文件。因此，当虚拟机本身写入文件时，它实际上是在遍历这个文件，这与容器直接匹配文件的欺骗非常相似。但是有一些实际的不同。首先是虚拟机非常强大。你可以使用它们运行其他操作系统，如 Mac OS 或 Windows，以及不同的硬件配置，你可以在 Linux 管理程序中模拟 gamecube 或 apple two。

在容器中，进程被欺骗了，它们肯定仍然是那种可以在 Linux 内部运行的东西。但在虚拟机中，有一个嵌套的操作系统，它通常不知道它不是在与真正的硬件对话。例如，当操作系统向其驱动器写入内容时，这些权限被发送到 Linux 中的一个文件，而不是物理驱动器。

因此

当进程写入虚拟机中的操作系统时，操作系统将权限发送到驱动器，或者它认为是驱动器的东西，但该驱动器通过 Linux，Linux 实际上将它映射到文件。

各种基准测试显示，CPU 和 VM 大约比容器慢 10%到 20%。虚拟机通常还会多使用 50%到 100%的存储，因为它们需要操作系统需要的所有东西。复制容器不需要所有的文件，它们只需要应用程序文件。最后，虚拟机为操作系统本身多使用了大约 200 兆字节的内存。同样，容器不需要所有的操作系统，因为它是被欺骗的进程。因此，虚拟机使用更多内存，速度更慢，并且需要更多存储。

因此，考虑到这些性能优势，容器似乎总是更好的选择。然而，在大多数情况下，虚拟机是更好的选择。同样，虚拟机指的是虚拟机。

如果你运行在不可信的，用户提供的代码中，很难确信他们不能逃离容器。这一点近年来有所改善，但长期以来一直是一个有争议的问题。虚拟机要古老得多，也成熟得多。所以如果你运行的是不可信的代码，通常把它放在一个容器里是个好主意。

如果您运行的是 Windows 或 Mac OS 脚本，那么您运行的脚本只能在另一个操作系统上运行，出于类似的原因，您需要使用 VM。或者，如果你正在运行一个不能在 Linux 上运行的旧视频游戏，而你想在一台 Linux 计算机上运行它，你需要 VM。反之亦然，如果你使用虚拟机和其他操作系统，如果你想在 Windows 中运行 Linux 程序，你通常必须使用虚拟机来运行它。

最后，您可以使用虚拟机模拟显卡等硬件设备。

因此，如果您正在测试您的图形卡是否正常工作，您可以模拟它将给出的响应，然后测试操作系统是否按预期工作。

这就是虚拟机和容器之间的巨大差异。这确实是您经常部署的两个东西。因此，让我们在下一次演讲中探讨实际的部署策略。我在那里等你。

让我们继续讨论部署。所以滚动部署是最流行的部署策略之一。在本节中，我们将讨论不同部署策略的优缺点。滚动部署本身的工作方式是启动新版本的应用程序，向新版本发送流量以确保一切正常，然后展示旧版本并重复这一过程，直到旧版本的所有版本或新版本的所有版本。我意识到我说过很多次版本。因此，让我们来看看有助于说明这一点的图片。

这是 myrn 应用程序。myrn 代表 MongoDB，Node JS，react，express js。在这里，用户的 web 浏览器连接到前端和后端，前端是用户看到的东西。后端是提供数据库连接的服务。所以如果你登录，你就连接到了后端。如果你只是查看登录页面，你是连接到前端。假设你的应用程序有足够的流量，如果它暂时关闭，用户会注意到。您如何在不导致停机的情况下推出新版本的应用程序？这就是滚动部署的用武之地。滚动部署的高级算法如下所示。所以你创建一个新版本后端的实例，比如说，你一直等到它启动。所以你不断尝试连接到它，直到你得到一个满意的回应。然后删除旧版本，将流量路由到新版本。如果旧版本的任何实例仍然存在，请返回到第一步并重复。

在我们的 myrn 示例中，我们最初会看到初始版本的三个实例和新版本的一个实例。我们会重复这个过程

直到我们有了新版本的三个实例和初始版本的一个实例。这里，所有的版本都是后端。

我们添加了新后端的新版本。我们关闭了一个旧版本的后端。我们一直在重复。所以随着时间的推移，红色的取代了粉色的。这样循环几次后，剩下的只有红色的，我们加了一个红色的，去掉粉色的，加了红色的，去掉粉色的。“我们是红色的”是该应用程序的最新版本。

那么，与其他部署方式相比，滚动部署有什么好处呢？他们得到了很好的支持。滚动部署实现起来相对简单。在大多数情况下，它们是本机支持的。如果你听说过 Kubernetes，例如，Kubernetes 可以帮助你。AWS，Amazon Elastic Beanstalk 也支持滚动部署。

它们没有巨大的爆发。在我们将要讨论的另一种部署策略中，如果您有三个版本的后端，您总共需要启动六个版本来部署新版本，然后关闭旧的三个版本。因此，在部署期间，运行的事物数量会翻倍，例如，如果您的服务器数量有限，这可能会很困难。对于数据库这样的服务来说，限制连接的数量也并不少见。因此，如果有六个版本的后端连接到数据库，现在可能会给数据库带来太多的负载，因此可能会导致问题。

事实上，部署很容易恢复。如果在升级过程中，您注意到了问题，通常很容易逆转滚动部署，只需反其道而行之，删除红色添加粉红色，

您也可以反过来进行回滚，这是部署的一个重要特征，因为事情总是会出错。

滚动部署的缺点是运行速度慢。因此，如果您有 100 个副本，并且您一次替换一个副本，需要 20 秒，那么替换所有版本需要 2000 秒，这对于部署来说是相当长的时间。

这可以通过增加一次打开和关闭的服务数量来缓解，这有时被称为突发限制或滚动部署大小。

另一个问题是 API 兼容性，这是滚动部署的最大问题。因此，如果您向后端添加一个新版本的 API 端点，并在前端使用它，那么由于您不会同时切换它们，您可能会让后端的版本 1 服务于对前端版本 2 的请求。然后那个 API 就不存在了，所以在部署期间用户会看到错误。这可以通过复杂的路由技术来缓解，但是通常最好让 API 向后兼容。所以要让前端的版本二和后端的版本一兼容。因此，滚动部署相对容易理解，并且通常得到很好的支持。如果您的用户介意停机时间，那么使用滚动部署策略进行部署是非常好的第一步。关键的编程考虑是确保服务可以使用旧版本和新版本的服务 API。如果违反了此合同，用户可能会在部署期间看到错误。再来说说部署策略。我们将进入蓝绿色部署。

人们经常看到的另一种部署策略是蓝绿色部署。建立一个蓝绿色的。部署团队需要明确哪些服务将被一致地部署，哪些服务将在应用程序的不同版本之间共享。在下一节中，我将进一步解释我的意思，数据库服务器将是一个共享资源，应用程序的多个版本将同时连接到服务器，标准部署通常不会升级或修改数据库。

在我们的 mern 示例中，所有其他服务或集群资源，它们的新版本将部署在每个生产推送上。

因此，在蓝绿色部署策略中，当您升级 JavaScript 或 myrn 应用程序时，看起来应该是这样的。因此，有一个蓝色版本和一个绿色版本的应用程序，每个版本都是完全独立的堆栈。但是我们每个人都连接到一个共享的数据库，而这个数据库不是蓝色或绿色的一部分。这是由两个 bluegreen 部署使用的共享资源之所以这样称呼，是因为它们维护两个独立的群集，一个命名为 blue，另一个命名为 green，这与惯例不符。如果应用程序的当前版本部署为蓝色，我们将新版本部署为绿色，并将其用作一个准备环境，以确保新版本的应用程序在设置用户之前能够正常工作。

在我们确信新版本的软件工作正常后，我们将生产负载从蓝色转移到绿色，然后以相反的方向重复这个循环。所以在这里

我们首先将用户发送到 blue，它包含应用程序的第一个版本。然后我们正在研究第二版的工作原理。在我们确定第二版可行后，会将用户转到第二版。然后版本一就不用了。我们可以关闭它，用第三版替换它，确保它正常工作，然后一次又一次地将用户流量转移到它上面。在好处方面，蓝绿色部署在概念上非常容易理解。要设置它们，您只需创建两个相同的生产环境，并向其中一个发送请求，这对于像 Amazon elastic load balancing 这样的服务来说相对简单。

它们也非常强大，运行时间更长的任务，如下载可以在流量切换到新版本后继续在旧版本的应用程序中运行。因此，如果一个用户已经建立了到绿色的连接，而你已经将其他人切换到蓝色，该连接可以继续完成它正在做的任何事情。因此，如果您正在观看视频，并且想要将它完全下载给用户，这可能需要几分钟，甚至在 prod 推送期间也可能会继续。此外，bluegreen 部署可以扩展到许多不同的工作流，我们将对此进行讨论。

bluegreen 部署有一些明显的缺点，例如，很难部署热修复程序来恢复更改，因为旧的集群可能正在运行更长时间的任务，并且不可切换到。因此，如果您有应用程序的第一个版本，您切换到第二个版本，您意识到第二个版本有问题，您可能希望很快推出解决这些问题的第三个版本。但是第一版将是唯一可以部署第三版的地方。所以你不能这么做。在集群之间转移负载也很棘手，如果资源自动扩展(我们将在后面讨论),并且负载是一次性转移的，新集群可能没有足够的资源分配来满足激增的请求，因为请求会一次性达到生产负载峰值。

最后，如果一个集群修改了共享服务，比如向数据库的表中添加一列，它可能会影响另一个集群，尽管它不是活动的集群。

这里是一些蓝绿色部署的常见扩展。正如我提到的，它们非常容易扩展。许多团队围绕 bluegreen 部署建立了高级工作流，以提高稳定性和部署速度。第一个想法是蓝绿色部署的自然延伸，我称之为彩虹部署，但我不认为它们有一个标准术语。有些团队不是只有两个集群，而是拥有任意数量的集群，比如蓝色、绿色、红色、黄色等等。这在您运行非常长的运行任务时非常有用。例如，如果您正在使用分布式 web scraper，并且您的抓取任务需要几天时间，那么您可能需要您的集群持续到最后一个作业完成，以确保事情按预期继续工作。因此，借助 rainbow 部署，您可以保留所有仍在处理任务的集群，或者，如果您正在对长视频进行视频编码，您不希望关闭正在对长视频进行编码的集群，因为这一工作必须重做。

在群集的常规部署中，只有在所有长时间运行的作业处理完毕后才会关闭。

一些团队严重依赖手工 QA，而不使用持续部署。他们经常构建桌面或移动应用程序，这些应用程序需要在更长的发布周期内发布。因此，如果 example.com 被路由到蓝色集群，那么将新版本的应用程序部署到绿色集群端点 new.example.com 就相对简单了。敬那个。通过这种设置，新版本的应用程序可以在即将投入生产的环境中针对生产数据库进行测试。这种测试通常被称为验收测试，因为它们发生在生产数据的生产中，没有任何特权访问代码库。所以对于一个游戏，你可能有新的版本，或者新版本的 API，并让你的 QA 测试人员测试。在 QA 测试人员批准后，您可以将游戏客户端指向新版本，然后将的标签切换到

bluegreen 部署的另一个有用附件。真正的部署通常被称为金丝雀部署。因此，如果你的应用程序的新版本包含主观上的改变，比如编辑用户界面，把它们一次推给所有用户可能是不明智的。脸书有数十亿用户。因此，即使只有 1%的用户抱怨某个变化，那也是巨大的反馈。这些更改可能会中断用户工作流，并且需要根据用户反馈进行修改或回滚。因此，在蓝绿色部署的上下文中，金丝雀部署将是一个扩展，它将 5%的用户流量路由到应用程序的新版本。并在切换其余用户之前检查这些用户没有负面反馈。所以如果蓝色是第一版，绿色是第二版，我们有 95%会选择第一版。5%转向第二版

我们等着看第二版是否有人抱怨。如果没有，那么我们会把每个人都送到第二版。我们关掉第一版，然后把第三版放在那个里面。

因此，bluegreen 部署是强大且可扩展的部署策略，适用于每天部署几次的团队。有了策略才真正开始有问题。它可以使用部署场景，在这种场景中，每天要部署许多次服务。

好吧，让我们继续讨论部署。下一次演讲再见。

持续部署听起来令人生畏，但在许多情况下，它实际上并没有看起来那么困难。让我们回顾一下我们当前的例子，以及它是如何部署的。

因此，在我们的自述文件中，我们添加了这一行非常有用的内容，这也是我们目前部署到生产环境中的方式。

如果我们看看我们的托管版本 slug，它托管在这个域中，我们可以看到颜色仍然是紫色的，尽管在前面的视频中已经将颜色改为蓝色。

它仍然是紫色的原因是我们还没有推出产品，我们还没有推出新版本的代码，其中包含蓝色。

通常，需要人工干预来部署是不可行的，尤其是作为产品技能。因此，要进行部署，我们先手动运行部署流程，然后再讨论如何使用持续部署系统实现自动化。

所以在这里，我们将使用一个终端，直接从 read 运行命令。

这台开发人员计算机带有部署所需的 SSH 密钥，否则很难将这个 SSH 密钥分发给所有开发人员，因为他们需要部署新版本的代码。

这里我们可以看到它使用了 Docker compose rebuilt，我们将在后面讨论如何建立 Docker 文件。

现在，如果我们刷新页面，

我们可以看到部署已经创建了一个新版本的应用程序，它是蓝色的，所以它选择了在之前的提交中合并的颜色变化。

因此，连续部署，我们希望它运行在主分支的合并上，我们不希望在功能分支被审查之前部署它们。为此，我们可以设置一个非常简单的配置。

我们可以把这个配置文件写在任何目录中，但是现在让我们把它写在 API 目录中。

因此，我们将创建另一个层文件

将从测试层文件继承，以确保部署在测试通过后运行。

并且仅当分支是主分支时才运行部署。

但是，如果它是主分支，我们希望设置一个秘密，并将该秘密用于我们的 SSH 密钥，然后使用该 SSH 密钥运行脚本。

让我们现在做那件事。

然后很有希望给我们提供暴露 SSH 密钥所需的指令。

什么是反对？

现在，我们公开 SSH 密钥，它用于在 CI 流程本身中对生产机器进行身份验证。

我们需要做的另一件事是改变所有权，使其更具限制性。这对于 SSH 是必需的，但是对于其他部署过程可能不是必需的。

现在我们在 CI 服务器中有了 SSH 密钥，并且这些步骤在测试通过后运行，我们所要做的就是复制我们的命令并运行它，就像它是 CI 流程的一部分一样。

这个配置所做的就是等待测试通过，检查分支是否是主分支，然后使用 SSH 密钥部署应用程序的新版本。

让我们用这些更改创建一个新的拉请求，看看它是什么样子。

我们可以看到，像以前一样，短暂的环境和 ci 服务已经建立。但是这个 API 服务也在构建中，API 是包含我们持续部署过程的目录。让我们来看看是什么管道

实际上看起来像结构。

所以这里我们可以看到

该应用程序已经成功构建，并且正在启动，就像在没有 CD 的常规 ci 过程中一样。因此，我们正在运行我们的持续集成，但不是我们的持续部署步骤和这个层文件。

我们可以看到测试正在运行。

和往常一样，测试运行过程需要启动一个假的浏览器。这大约需要 30 秒。

测试通过后，我们将看到部署流程开始运行。所以测试导致了第二个层次。

图，这些通常被称为 CI CD 系统中的构建阶段。

所以在这里，我们可以看到

这个步骤被跳过了，因为这个分支不是主分支，这正是我们想要的。但是，现在如果我们合并这个拉请求，

我们将在主分支上创建一个新的合并分支。我们将再次运行 CI 流程。

给你。

因为这是主分支，部署过程本身将会运行。让我们来看看它是什么样子的。

我们现在只是加载环境来运行命令。

在这里，我们可以看到部署正在 ci 内部运行。因此，您可以在 ci 中简单地运行这个 SSH 命令，而不需要以个人开发人员的身份运行它。这种从 CI 流程自动部署的想法称为持续部署。

因此，让我们从头到尾完成整个流程一次，以确保部署自动化方面的事情一目了然。

因此，让我们再次更改主登录页面的颜色，以确保如果更改被正确推送，它是可见的。

同样，我们将改变这两种颜色。

我们将创建一个新的拉取请求。

而现在我们的评审员会有很多关于这个变化好不好的信息。因此，审阅者将能够看到两个文件都发生了更改。

所以他们会看到我们只是改变了一些颜色，

我们将能够看到 CI 流程本身。

这样他们就能看到测试正在运行。

特别是，应用程序构建成功启动，测试运行，

他们将能够在我创建这个新变化的几分钟内看到一个短暂的环境。

如果他们同意这一改变，它会在很短的时间内显示给用户，整个过程只需要一分钟左右，最长的部分是这些自动化的浏览器测试。

一个接一个，这些步骤应该变成绿色。

还是那句话，这是基础。这是短暂的环境。这是一个持续的部署过程。这是鸡蛋的状态。这是 GitHub 管理员可能标记为必需的。因此，只有通过了所有检查，提交才能被合并并显示给用户。所以这里可以看到一切都过去了。让我们来看看短暂的环境，只是为了再次检查颜色是我们想要的。

我们可以看到，从热环境来看，我们把颜色变成了玫瑰红，也许这就是我们想要的颜色。所以我们会说这是正确的。并且测试已经通过，成功发布消息。因此，我们知道，在这种变化之后，应用程序的功能继续工作。

在我们合并之后

成为此合并提交的端到端测试部署流程。

如果我们看看这个，

我们会看到，因为我们合并到主分支

部署已经在运行。在生产中，我们正在创建一个生产版本。在很短的时间内，生产服务器上应该会运行我们应用程序的最新版本。这里，它正在重启生产实例。

正在拍摄快照。所以一切都是成功的，我们已经成功地推动了如果我们去我们的网站，它现在是红色的阴影，我们已经改变了。这就是端到端 ci CD、短暂环境管道在很高层次上的一般情况。

好了，让我们在下一节中更多地讨论部署自动化，

讨论了部署策略。但这并不是部署中的唯一内容。部署策略可帮助您减少停机时间，并以不影响用户的方式进行部署。但是部署的另一个关键考虑是确保有足够的资源用于容器或虚拟机。因此，如果用户数量激增，您的应用程序不会宕机。

假设你正在建立一个竞争情报系统，这很切中要害，因为我在竞争情报公司 layer ci 有课程，

您的用户会推送代码，您必须启动运行程序来运行针对该代码的测试。在用户工作时间，你会看到流量激增。在营业时间之外，你会发现交通流量明显减少。对于 10，000 个并发运行的峰值负载，您至少需要提供 10，000 个运行程序。

然而，在晚上，高峰时间之外，你并不真的需要所有的 10，000 名跑步者，他们中的大多数人会无所事事。

因此，您的使用可能看起来像这样，这也是许多应用程序的指示，您的最低点可能是 500。需要跑步者，你的最高点是需要 10，000 名跑步者。所以从一天的最高点到一天的最低点，你需要多 20 倍的工人。

在一个理想的世界中，你可以根据需要创建或销毁这些跑步者。在高峰时段，您可以创建新的，然后在非高峰时段，您可以销毁它们。这就是自动缩放的想法。

因为云提供商，它只能创造和毁灭工人。在他们巨大的规模下，以一小时的小租金提供廉价的服务器是可能的。在这篇文章或这段视频中，最流行的技术是 AWS easy-spot instances，它的行为完全类似于云托管的虚拟机，如果您在短期内提供它们，会有很大的折扣。另一种流行的自动缩放技术是 Kubernetes 水平 pod 自动缩放，这听起来令人生畏。但是由于许多提供商都提供现成的 Kubernetes，所以您可以假设如果您使用 Kubernetes 和容器，只要您正确配置，就可以自动伸缩。举例来说，如果您使用微软的作为您的云提供商，有资源可以自动扩展虚拟机。还有集装箱。如果您使用 AWS，还有虚拟机和容器的资源。如果你使用谷歌云，有虚拟机和容器的资源。自动缩放通常是在一个小时的工作块的时间线上讨论的。如果您采用自动伸缩的概念并将其发挥到极限，您将获得快速启动的无服务器定义的资源，并在毫秒的时间线内使用它们。所以 1 到 100 毫秒。

例如，在访问者请求页面之前，web 服务器可能根本不需要存在。相反，它可以专门为该请求启动，服务于该页面，然后关闭。

这正是无服务器的理念。这几乎就像自动扩展一样，根据需要配置资源，并在很短的时间间隔内快速完成。

无服务器主要用于无状态下启动速度较快的服务，您不会在无服务器框架内运行类似 CI 作业或 CI 运行的内容。但是您可能会运行 web 服务器或通知服务之类的东西。

自动扩展主要用于启动较慢或需要状态的服务，您可能会在自动扩展的虚拟机或容器中运行 CI 作业，而不是在无服务器容器中。

作为一款 2021，车型之间的区别变得相当模糊。无服务器容器正变得流行。他们经常跑一个多小时。无服务器容器的行为与容器完全一样，但是它们是以无服务器的方式创建和关闭的。所以当一个触发器触发时。

几年之内，无服务器和自动扩展很可能会融合到一个统一的界面中。所以我对此很兴奋。这将是部署的未来。

我们对自动扩展和无服务器的讨论到此结束。下次演讲再见。

部署自动化的另一个关键概念是服务发现。

一个数据库可能在一个 IP 地址，所以 10 点 1.1 点 1.6 乘 4 点 3 任意选择，而 web 服务器将在另一个 IP 地址 10.1 点 1.2 点 8080。

他们必须相互发现，因为 web 服务器需要与数据库通信，而数据库可能会调用 web 服务器，当您添加更多的 web 服务器副本或添加全新的服务时，这些会变得更加复杂。同样，让我们考虑一下 academy DevOps 系列中其他地方的 myrn 应用程序。

所以你有一个网络浏览器，用户自己正在访问你的网站。它们连接到您的前端，并连接到您的后端进行 API 调用。你的后端连接到一个数据库。

在这里，有三种服务需要被发现。浏览器需要知道 example.com 对应于前端，example.com 斜杠 API 对应于后端。而后端需要登陆数据库的是，比如 10.111 点 1.3。所以后端需要知道数据库的 IP 地址和端口。而且浏览器需要知道后端和前端的 IP 地址和端口。在最简单的配置中，一切都是手动配置后端和前端或添加静态 IP。给定 DNS 域名系统中的主机名，这是 example.com 到互联网上的 IP 地址的映射。后端被配置为在特定端口连接到 MongoDB。您的 DNS 配置，这是 CloudFlare 配置页面，其中有一个 DNS 提供商，看起来像这样。因此，如果用户访问 example.com，发送到这个 IP 地址。

如果他们访问 api.example.com，就把他们发送到那个 IP 地址。所以这都是手动配置的。我们刚刚手动将 IP 地址放入其中。

然后在后端，我们会读取一个环境变量，这是一个键值对的字典，在部署时很容易设置。所以您会说连接到环境变量，指定 MongoDB 端口，

然后连接到端口 27017，这是默认的 MongoDB 端口。

然后当您启动后端时，您只需指定运行 MongoDB 的 IP 地址。

这个配置完全没问题。简单的产品，很难搞砸。它相对安全，不会使事情过于复杂，您可以通过简单的配置走得很远。大多数产品可以在没有任何服务发现的情况下启动 MVP。

但是，当您看到以下情况之一时，您将知道您需要开始考虑使您的服务发现复杂化。因此，您需要零停机部署。如果你想做滚动部署，你不能像这样硬编码。因为你不能容易地自动化箭头指向的地方，所以你不能自动改变 IP 地址。如果你在做这样一个简单的部署策略。例如，如果您有多个微服务，就很难记住它们都在哪里。如果您要部署到多个环境中，例如，如果您有一个开发环境、一个试运行环境、一个临时环境和一个生产环境，这些环境都有不同的 IP 地址，那么到处设置 IP 地址将会变得非常困难。因此，让我们关注零停机部署，因为它们说明了更广泛的问题。不过，在此之前，我们先来谈谈反向代理，这是另一个至关重要的系统设计和 DevOps 概念。零停机部署的想法很简单。正如我们所看到的，您启动新版本的后端和前端，等待它们启动，然后关闭旧版本的后端和前端。因此，滚动部署和蓝绿色部署都会出现这种情况。然而，很难更新 DNS 本身的 IP 地址。如果我们的滚动部署需要直接在 DNS 中更改这些值，由于各种原因，这样做不会很好。特别是，DNS 可能需要很长时间才能在美国以外的其他国家传播用户，例如，可能需要几天才能看到新的 IP 地址，而他们仍然会尝试连接到旧版本。

解决方案是添加一个 web 服务器作为前端和后端的网关，我们能够改变它指向的地方，而不改变 DNS 配置本身。所以像这样的网络服务器被称为反向代理。它们对于建立零停机部署和服务发现本身来说非常重要。

因此，采用我们的 myrn 应用程序并增加这一级别的复杂性，用户的网络浏览器将改为连接到反向代理。所以用户会问 DNS 系统 example.com 在哪里

DNS 系统会回应，哦，它在这里，

反向代理的 IP 地址。然后，反向代理会接受用户的请求，并将其发送到适当的前端或后端，这取决于用户要求连接的内容。然后从那里开始，其他一切都将是一样的。

因此，如果您正在运行部署，如滚动部署，代理可以选择前端或后端的 v1 或 v2 中的哪一个来发送用户请求，只需更改配置文件即可。

部署完成后，您可以关闭第一版，反向代理可以将流量完全转移到一个简单的方法，即将服务 IP 存储在哈希表中。因此，在目前运行的过程中，我们假设我们的反向代理能够知道我们应用程序新版本的 IP，这正是服务发现的声明。因此，需要手动告诉我们的反向代理前端和后端住在哪里。那么，我们后端的第二版的 IP 地址在哪里呢？如果我们能够实现自动化，这将非常方便。

当新版本上线时，它们可以用自己的 IP 在这个哈希表中更新密钥后端和前端的值。然后，反向代理可以观察表的变化，并将其用于路由决策。

举一个非常具体的例子，这是我们在这组视频中最接近代码的例子，让我们看看这个 nginx 配置。nginx 是一个非常流行的反向代理。这在大型科技公司中非常普遍。

它可以让你定义各种主机名的去向，如果你把 example.com 指向 nginx，反向代理，同样，在图中，这将是 nginx，用户认为他们正在连接到你的网站，但他们会发送请求到 nginx。例如，COMM 和 nginx 会将它们的例子转发到您的实际前端。所以 nginx 只需要知道你前端的 IP 在哪里。这就是这种配置的作用。所以我们直接告诉 nginx，

从这个文件里拿出这把钥匙，

然后使用 conf D，它从散列表中读取并更新配置文件，然后将用户发送到那里。因此

您需要的只是一个键值存储，它有一个密钥卡，其中前端 IP 是当前的前端版本。然后，要运行滚动部署，您需要启动一个新的前端版本，检查它是否处于活动状态，然后您只需更改哈希表中的键以指向新版本。然后不断地获取更改，用前端版本 2 的新 IP 替换这个值，然后重新加载 nginx，这样会将箭头更改为前端的新版本。

这是一个很大的挑战。因此

让我们后退一点，您需要做的只是更新您的前端，在哈希表中将 IPS 前端的键设置为前端 IP，然后让您的后端对后端位置进行同样的操作。这样，当应用程序的新版本启动时，它会更新表中的键。然后 nginx 会开始将用户路由到应用程序的新版本。

这就是代理传递和 nginx 的含义。你会看到这个代理传递指令。但这一切都很复杂。这只是一个说明，如果你要自己实现它，你会怎么做？

工业上最常用的是利用 DNS 本身进行服务发现。因此，我们以前认为 DNS 是一种缓慢的协议，可能需要几天时间才能在网络中传播变化。但是可以在本地运行 DNS。

这是行业标准。

所以让我们稍微谈一下 DNS。

DNS 的想法只是将主机名映射到 IP。当你访问 ci.com 层。例如，全球 DNS 系统将首先将 latest.com 这个名字映射到这段视频播放时的地址 104 点 217 9.86 和 172 点 6 7.16 9.106，这些地址只是连接到互联网的任意计算机。你可以在网站上使用 Digg 命令来查看这些地址在哪里。这就是说关键层 ci.com 的值是这两个。

通常当人们提到 DNS 时，他们指的是全球服务。所以在互联网上访问网站。然而，正如我提到的，在内部运行 DNS 是可能的。如果在我们的 nginx 配置中，我们可以指定 HTTP 全冒号加斜杠的前端，然后让前端解析到我们的前端服务的 IP，这将是理想的。这样，除了 DNS 配置之外，我们不需要改变任何东西。

这正是基于 DNS 的服务发现的工作方式。您配置您的服务来查询您控制的服务器的 DNS 查询，然后这个

所以不要说 MongoDB，全冒号斜杠，process 和 MongoDB，你只要说 MongoDB 全冒号斜杠 Mongo，其中 Mongo 是你控制的 DNS 中键值对中的一个键。

当然，部署自己的 DNS 服务器也不是小事。在实践中，虽然有核心 DNS 等流行的选项，但您最有可能做的是使用云提供商或 Kubernetes 内部解决方案。

所以你得到的最终结果是这样的，用户的网络浏览器会连接到 nginx。考虑到这是一个网站，nginx 会问 DNS 提供商，API 现在在哪里，云提供商会回答这是 IP 地址，考虑到部署，所以蓝色、绿色或滚动部署，这是我们目前希望用户在访问 API 时访问的内容。然后

这将对应于后端的版本 1 或版本 2。然后代理会将请求转发到那里，请求被满足，然后我们回到代理，再回到用户。

因此，所有这些的结论是，服务发现是棘手的，但作为这些部署策略的基础构建块是至关重要的。对于一般的部署自动化来说，如果您以适当的方式为您的部署配置服务发现，例如基于 Kubernetes 集群的 DNS，这将使开发人员更容易拥有相互通信的微服务，而不是让开发人员编写连接 MongoDB 应用程序，然后处理 MongoDB 的实际位置。他们可以简单地说在 MongoDB 冒号斜杠斜杠 Mongo 处连接到 MongoDB。然后，作为 DevOps 平台工程师，您可以配置 Mongo 始终指向正确位置的正确 IP 地址。通过将应用程序逻辑从部署逻辑中分离出来，您将帮助团队中的开发人员更快地构建，并且您将能够更容易地部署它。部署到此为止。让我们继续下一个也是最后一个支柱，即应用程序性能管理。

应用程序性能管理中没有太多的通用主题，所以这一部分会稍微短一点。我们将在 DevOps Academy 的未来章节中进行更详细的介绍。但是就这个入门视频系列来说，我们来谈谈两个核心概念。第一个是日志聚合。这是一种将来自许多不同服务的应用程序日志收集并标记到一个易于搜索的仪表板中的方式。在应用程序性能管理系统中，首先要构建的系统之一是日志聚合。提醒一下，应用性能管理是 DevOps 生命周期的一部分，是构建和部署的地方。你需要确保他们持续工作，这样他们就有足够的资源分配给他们。错误也不会显示给用户。

在大多数生产部署中，有许多跨服务发出日志的相关事件。在谷歌，一个搜索在返回给用户之前可能会找到五个不同的服务。如果您得到意外的搜索结果，这可能意味着这五个服务中的任何一个都存在逻辑问题。日志聚合帮助像 Google 这样的公司诊断生产中的问题，他们建立了一个单一的仪表板，可以映射每个请求的唯一 ID。因此，如果你搜索某个东西，你的搜索将获得一个唯一的 ID，然后每次搜索都通过不同的服务，该服务会将该 ID 与他们当前正在做的事情联系起来。

这是一个好的日志聚合平台的本质，有效地从发出日志的任何地方收集日志，并使它们易于搜索。在出现故障的情况下。同样，这是我们的主应用程序，用户的 web 浏览器连接到后端和前端，然后后端连接到数据库。

如果用户告诉我们，页面变白并打印出错误信息，我们将很难诊断当前堆栈的问题，用户将需要手动向我们发送错误，我们需要将它与其他三个服务中的相关日志进行匹配。让我们来看看 Elk，这是一个流行的开源日志聚合堆栈，以其三个组件 Elasticsearch、LogStash 和 cabana 命名。

如果我们将它安装在 burn 应用程序中，我们将获得三项新服务。因此，用户的 web 浏览器将再次连接到我们的前端和后端。后端将连接到 Mongo，所有这些服务、浏览器、前端、后端和 Mongo 都将日志发送到 LogStash。

然后这三个组件的工作方式，ALK 弹性搜索日志存储和小屋的组件是所有其他的

服务将日志发送到 LogStash。LogStash 获取这些日志，它们是应用程序发出的文本。例如，网络浏览器。当您访问一个网页时，该网页可能会记录此访问者此时访问了此页面。这是一个日志消息的例子。这些日志将被发送到 LogStash，LogStash 将从中提取内容。因此，对于日志消息，用户做了一次事情，它将提取时间、提取消息、提取用户并包括所有这些作为标签。因此，消息将成为标签和消息的对象，以便您可以轻松地搜索它们。您可以说，查找特定用户发出的所有请求。

但是 LogStash 本身并不存储东西。它在 Elasticsearch 中存储东西，elastic search 是查询文本的高效数据库。弹性搜索将结果显示为 Kibana

cabana 是一个连接到 Elasticsearch 的 web 服务器，它允许管理员作为开发人员或您团队中的其他人，即待命工程师，在出现重大故障时查看生产日志。

因此，作为管理员，您可以连接到 cabana cabana，查询 Elastic Search，查找与您想要的内容相匹配的日志。你可以说，嘿，cabana，在搜索栏中，我想找到错误。cabana 会说弹性搜索找到了包含字符串错误的消息。然后 Elasticsearch 将返回由 LogStash 填充的结果，而 LogStash 将是来自所有其他服务的样本结果。如果您访问了一个网页，这可能是发出的日志类型。

它可能会被加工成这样的物体。所以它有一个格式，一个日期，和一个简单的时间格式。所有不同服务发出的所有消息都是一样的，你会有一个服务，该服务提交日志，你会有消息，日志的实际内容。

和处理器，LogStash 本身通常会连接到互联网，以便浏览器中的 JavaScript 可以捕捉错误并将其发送到 LogStash。虽然还有其他服务，比如 century，可能更适合这种情况。我们如何利用麋鹿来诊断生产问题？好吧，假设一个用户说我看到了错误代码 1234567。当我尝试这样做时，通过 elk 设置，我们必须去 cabana，在搜索栏中输入 1234567，按回车键。然后会显示相应的日志。其中一个日志可能会说，内部服务器错误返回 1234567。我们会看到发出日志的服务是后端的，我们会看到博客是什么时候发出的。所以我们可以找到日志中的时间。我们可以在后台查看它上面和下面的消息。然后我们可以更好地了解用户请求发生了什么。

我们可以对其他服务重复这个过程，直到我们找到用户真正的问题所在。

难题的最后一部分是确保日志只对管理员可见。由于日志可能包含令牌等敏感信息，因此只有经过身份验证的用户才能访问它们，这一点很重要。你不会想在没有某种认证的情况下将 Kibana 暴露在互联网上。我最喜欢的方法是添加一个类似 nginx 的反向代理。同样，我们的朋友 nginx 然后让 auth request 机制检查用户是否登录。所以在我们的后端，我们可以添加类似这样的东西，它只是返回一个成功的状态。如果用户访问 example.com 斜线认证请求，并有一个管理员，它会返回一个成功的状态。如果他们不是管理员，就会返回一个未授权的状态。然后我们可以配置 nginx。同样，正如前面视频中提到的，要拥有这些位置块，slash 私有位置将连接到 slash off。然后，我们可以确保如果这是斜杠日志，例如，用户已登录，因为使用这个 auth request 指令，如果用户访问斜杠日志，并且他们不是管理员，他们将无法访问它们。或者，Elasticsearch 本身由一家名为 elastic 的公司运营，他们有一个付费版本，其中包含一个名为 x pack 的东西，这也有助于实现这一点。因此，您可以选择验证用户身份的反向代理，或者付费版本的应用程序。

顺便说一下，您可以使用日志聚合作为额外的测试。因此，在您的 ci 管道中，当您想要判断代码是好是坏时，您可以重新调整您的日志聚合堆栈，以确保在测试运行时不会出现警告或错误。如果您的端到端测试看起来像这样。所以你开始你的堆栈，你开始你的日志堆栈。您正在使用 NPM 运行测试来运行您的测试。您可以添加一个额外的步骤来查询日志匹配错误的弹性搜索，并且您可以确保

没有日志，打印错误。然后，即使你所有的测试都通过了，如果有一个错误正在发生，尽管所有的测试都通过了，这个错误可能还是很重要的。因此，这为您的 ci 堆栈增加了一项免费的额外检查。

这里有几个日志聚合平台的例子。有 Elasticsearch，LogStash，Kibana，我们谈到过，还有 fluent D 是另一个流行的开源选择。有一种数据狗，在大型企业中非常常用。这是一个托管服务。还有 log DNA，这是另一种托管产品。这些云提供商还提供日志记录工具，如 AWS、cloudwatch 日志。因此，日志聚合是诊断生产中问题的关键工具。安装 elk 或 cloud watch 这样的交钥匙解决方案相对简单，而且它使诊断和分类问题以及生产变得非常容易。这就是日志聚合。下次演讲再见。

另外，我们要讨论的主题是度量聚合。指标只是告诉您生产健康程度的数据点。正如您在屏幕上看到的，CPU 使用率、内存使用率、磁盘 IO、文件、系统满度等都是您可能关心的重要生产指标。如果日志聚合是为生产监控设置的第一个工具，那么指标监控将是第二个工具。它们对于发现产品故障、调试性能和稳定性问题都是不可或缺的。

日志聚合主要处理文本，当然日志还是文本。相比之下，指标聚合处理的是数字。他的记忆被利用了多久？

理解生产系统中发生的事情非常困难。例如，网飞测量了 25 亿个不同的时间序列，以监控其生产部署的运行状况。成功的指标监控能够在生产中出现问题时自动通知必要的团队。

让我们继续查看 DevOps 工具的开源实现，以保持通用性。Prometheus 是一个最初部署在 SoundCloud 的工具，是最受欢迎的度量服务器之一。这是它看起来的样子。类似的结构，输入被发送到检索，像节点会发送他们有多少磁盘使用量给媒体服务器，而且服务需要多长时间 ALC 本身会解析日志中的数字并发送它们以允许这一点。然后，promethease 从前面的视频中找出使用服务发现可以获得哪些服务。然后它把这些数据存储在一个时间序列数据库中，这个数据库相当于数字，就像 Elasticsearch 相当于文本，然后存储在 Prometheus 服务器节点上。

最后，还有一个前端。所以其他服务可以查询 promethease。要做的事情，你可能想做的一件事是，如果有什么可怕的错误，比如你的网站关闭了，你可能想连接一个传呼机或发电子邮件或用 Twilio 给某人发短信，而不是打电话给工程师，告诉他们有问题。

但是您可能还想查询指标来获得类似这样的视图。这就是 prom qL 的用途。所以 grafana 是黑暗的视图。这是观察这些时间序列的常见方式。但是你可以自己做，也可以做 API。还有许多其他前端连接到先前的。

上图令人望而生畏，但它与我们讨论的日志聚合框架的架构非常相似。有四个关键部分。正如我提到的，时间序列数据库实际上存储了测量、检索、警报管理器和 web UI。

所以我们收集的指标。嗯，基于你的产品做什么和你的用户是什么，关于哪些指标是重要的有很多主观性。但是这里有一些关于在类似普罗米修斯的东西里储存什么的想法。

因此，请求实现时间对于理解系统何时过载，或者新推出的变更是否对性能产生负面影响非常有用。

例如，格式化时间通常使用正则表达式从日志中解析出来，或者从数据库的字段中提取出来。

对于一个网站或 rest API，一个常见的请求实现时间是对网站和 REST API 的响应时间。常见的请求实现时间是响应时间。

这样，慢速网页可以在生产中被发现和识别。

这是一个相关的指标，非常能说明他的请求计数的问题，如果每秒的请求数有一个巨大的峰值，那么很可能至少有几个生产系统在扩展时会有问题。观看请求计数也可以用于检测和

减轻诸如拒绝服务攻击之类的攻击，拒绝服务攻击是指攻击者向生产中的服务发送许多恶意请求。

许多类型公司的最后一个通用指标是服务器资源。这里有几个例子。所以数据库大小和最大数据库大小。如果您的数据库有 2tb 的磁盘，而中有 1.5，那么您可能希望提醒某人增加数据库的可用磁盘量，或者删除未使用的 web 服务器内存。因此，如果您的 web 服务器每秒接收大量请求并进行大量处理，它可能需要更多内存。因此，如果它耗尽内存，它会崩溃，你的用户将无法访问你的网站了。

网络吞吐量。所以如果你下载了很多东西，或者上传了很多东西，你的网络就会饱和。这也会导致性能下降。最后一个是 TLS 证书到期时间。因此，浏览器中的这种锁使用 TLS 证书来查看浏览器是否安全，在内部到处都在使用。如果没有被测量，没有被提醒，这些就会引起问题。举例来说，谷歌语音在 2021 年出现了中断，所有公司中的谷歌都没有衡量他们的 TLS 证书何时到期。这导致了几个月前的停电。

所以生产故障很少看起来像没有用户可以访问任何东西。通常会有一个渐进的过程，某些 API 会花费越来越长的时间，最终一切都会崩溃。门户分析是将生产统计数据削减为可操作数据的简单方法。当有一个非常明显的生产问题时，一个网站可能会测量网站完全加载其登录页面需要多长时间才能注意到。因此，使用 cuartel 分析，您可以拆分请求时间和许多不同的时段。最慢的 1%用户用了多长时间？最慢的 5%用户用了多长时间？最慢的 25%的用户用了多长时间。因此，如果您的登录页面在用户登录和注销时变慢，只是在没有登录用户的情况下访问，您可能不会注意到网页非常慢。但是，已登录的用户会出现在 1%的请求桶中，您会看到这些用户有糟糕的降级体验。

或者，当示例 stackoverflow.com 自己被通知停机，因为他们的登录页面由于发布到堆栈溢出的特定帖子而花费很长时间来响应请求。对于度量分析，有许多常见的生产工具。这是普罗米修斯和格拉夫纳。正如我们提到的，还有数据狗，不仅仅是日志聚合，还有指标聚合。有新的遗物，我会说可能是旧的可靠的选择。同样，云提供商也有自己的版本。有 AWS cloudwatch 指标、Google 云监控和 as your monitor 指标。

这就是应用性能管理。感谢观看。