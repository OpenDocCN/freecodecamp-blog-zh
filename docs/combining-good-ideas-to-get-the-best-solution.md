# 如何结合好的想法来获得解决问题的最佳方案

> 原文：<https://www.freecodecamp.org/news/combining-good-ideas-to-get-the-best-solution/>

权衡存在于我们所有的活动中。也许你听过机器学习中所谓的“没有免费的午餐定理”。该定理指出，当涉及到机器学习模型时，没有灵丹妙药。但事实上，任何事情都没有灵丹妙药。

这不是计算机科学原理，而是经济学原理。

如果你已经写了一个多月的代码，你可能已经体验过编程中权衡的必要性——或者至少听说过它们。

有时你会以安全的名义牺牲性能，以可伸缩性的名义牺牲安全性，以性能的名义牺牲美观和可读性，等等。不要忘记，你也可能以编程的名义牺牲掉聚会和娱乐，所以让它变得值得。

在算法的具体情况下，主要资源是时间和内存，因此权衡总是涉及那些资源。

对于同一个问题，通常会找到几种解决方案，因为其中一种速度更快，而另一种在存储方面更便宜。当然，还有其他因素，如实现、简单性和安全性。

在这篇文章中，我将讲述如何将几个解决方案结合起来，得到一个满足你所有需求的解决方案。

首先我要展示一个有趣的想法，E.W. Dijkstra 提出的寻找质数。之后，我将展示我想到的一个想法，以获得一个结合了数组和链表的强大功能的数据结构。

## 要求

我假设您已经掌握了基本的编程技能，并对数组、链表和堆等数据结构有所了解。

您还应该对计算复杂度的 big-O 符号有所了解。

最后，你最好熟悉厄拉多塞的 tje Sieve 算法。如果你不是，你可以看看这个帖子[链接](https://www.geeksforgeeks.org/sieve-of-eratosthenes/)。

要理解我将要讨论的内容，不需要其他的先验知识。

## 两种算法，一个问题

问题是找到从 0(零)到 n 的所有质数。这是你在开始编程之旅时要学会做的那种问题。我想从最简单的解决方案开始。

### 朴素算法

在朴素算法中，我们迭代从 2 到 n 的所有数字`x`，然后我们检查`x`除了自身和 1 之外是否还有任何除数。最后一步，我们可以检查 2 和`x - 1`之间的每个数字`d`是否是除数。

最后一步还有改进的空间，因为我们只需要检查小于或等于 x 的平方根的除数，算法的一段伪代码写在下面:

```
 primes(N):
      prime_numbers <- [] # empty list
      for x = 2 to N:
          is_prime <- true
          for d = 2 to sqrt(x):
              if d divides x:
                   is_prime <- false # we found a divisor of x so x is not a prime number
          if is_prime:
               prime_numbers.add(x) # if we didn't find a divisor then x is prime
       return prime_numbers 
```

之前算法的运行时复杂度是多少？我们取从 2 到 N 的每一个数，对于每一个数，我们迭代所有可能的除数。所以我们进行`O(N*sqrt(N))`运算，其中`sqrt`代表平方根函数。

内存呢？我们只储存找到的质数。对于足够大的 N，素数的数量与 N 相比相对较小。因此，让我们将存储器复杂度表示为`O(Primes(N))`，其中`Primes(N)`是 0 和 N 之间的素数的数量。注意，这在存储器方面是最佳的，因为我们至少需要存储所有的素数。

### 厄拉多塞的筛子

你可能已经知道有一个更好的算法可以找到给定范围内的所有素数:厄拉多塞筛。我们来看看。

这个想法是维护一个长度为 N 的数组，其中每个条目不是假就是真。如果数组中第 I 个位置为真，那么我们说`i`是质数，否则`i`不是质数。

我们从所有具有真值的位置开始，然后对于每个位置，从`i = 2`开始，我们使`i`的每个倍数为假。

我们最终得到一个数组，其中每个位置的真值都代表一个质数。下面是经过一些优化的代码。

```
 primes(N):
        prime_numbers <- [] # empty list
        sieve <- a boolean list with length equal to N and all its elements set to true

        for i = 2 to sqrt(N): # we only need to analyze the numbers less than or equal to sqrt(N)
            if sieve[i]: # if sieve[i] is true then i is prime
                prime_numbers.add(i)
                for j = i*i to N: # we can start the inner loop in i*i
                    sieve[j] <- false
                    j <- j + i
         return prime_numbers 
```

可以证明，上述算法进行了优于朴素方法的 O(N log(N)) 运算。

甚至可以提高到 [O(N)](https://www.geeksforgeeks.org/sieve-eratosthenes-0n-time-complexity) ！但是我们需要存储一个包含所有 N 个数的数组，因此，我们最终会得到一个在内存方面更昂贵的算法。这里我们有一个权衡:时间换取记忆。

我们能设计出一种比天真想法更快，但在内存方面比厄拉多塞筛子更便宜的算法吗？

## Dijkstra 和生产线

在 60 年代，E.W. Dijkstra 在他的一份手稿中写了一个结合了天真和筛选思想的算法。但是在说之前，我们先分析一下前面两种算法的区别。

当应用朴素算法时，我们专注于分析每个数字是否是质数。当使用筛子时，我们分析每个质数及其倍数。这种差异可以用下面的类比来说明。

想象一下，我们想要制造几个产品，比如动作玩偶。我们有两种选择:一个接一个地建造它们，或者采用生产线，在每一个阶段，我们增加一个动作人偶的组件。对于后者，我们最终可以在更短的时间内生产更多的产品，但我们需要“生产线基础设施”。

Dijkstra 将这些想法结合起来，一次分析一个数字，但利用了以前的操作。我们可以维护一个已经被发现的素数池，并且对于这些素数中的每一个，存储尚未被分析的最小倍数。

例如:

如果我们正在分析数字 6，那么我们已经存储了素数 2、3 和 5，以及它们的最小未分析倍数:6 代表 2，6 代表 3，10 代表 5。

然后，当分析一个新数字时，我们取存储到那个时刻的最小倍数，如果这个倍数大于这个新数字，那么我们就找到了一个新的素数。否则，我们有一个合数，我们需要更新以新数为最小倍数的存储素数的倍数。

我们也开始存储倍数最小的质数`2`。然后当分析`3`时，我们发现`4 > 3`等于`3`是质数。我们存储`3`及其尚未分析的最小倍数(`6`)。当分析`4`时，我们发现`4`存储为`2`的倍数，然后我们更新`2`的倍数，现在将是`6`。当分析`5`时，我们发现`6 > 5`所以`5`是一个质数，我们将它与`10`一起存储，依此类推...代码如下所示。

```
 primes(N):
        primes_pool <- Heap( (4, 2) ) # a heap that contains a tuple with a prime number (2) and its least multiple that hasn't been analyzed yet (4).
        prime_numbers <- [2] # a list that contains the number 2
        for i = 3 to N:
            tuple <- getMin(primes_pool) # get the tuple with the minimum multiple, the prime number attached to it is irrelevant
            mult <- tuple.first # the multiple is stored in the first position of the tuple
            if mult > i:
                prime_numbers.add(i) # i is prime!
                primes_pool.insert( (i*i, i) ) # we insert i along with their least multiple, but it can be inserted i*i instead and the algorithm remains correct
                continue
            # otherwise i isn't prime and then...
            for t such that t is in primes_pool and t.first is equal to mult:
                t.first <- t.first + t.second # we update every tuple in the pool that has i as it's least multiple
        return prime_numbers 
```

前面的方法只存储质数和每个质数的另一个数。所以我们有一个与天真想法相同的记忆复杂度`O(Primes(N))`。

如果我们把质数和它们的倍数一起存储在一个像堆一样的结构中，我们得到的时间复杂度为`O(N*log N)`,和筛子一样。所以我们得到了我们想要的！

这里的技巧是，我们不需要标记给定素数的每个倍数，只需要标记最小的倍数。

我需要说，这不是一个实际的想法，因为厄拉多塞筛子的记忆复杂度没有那么差，而且这是一个非常容易实现的算法。

我的观点是，有时候，如果你有几个想法，但每个想法都因为一些缺陷而无法应用，那么结合它们的优势可能是一个好主意。这为您的问题提供了一个混合解决方案。

Dijkstra 的素数工厂教会了我这样思考，尽管我从未在现实生活中实现过这种算法。

## 用链表组合数组

数组是简单的结构，它允许我们在常量时间内通过元素的索引来获取元素。但是我们需要`O(N)`操作在最坏的情况下向数组中插入或从数组中移除一个元素，其中 N 是数组的长度。

另一方面，链表是由节点组成的结构。每个节点都有对下一个节点的引用，在双向链表的情况下，每个节点也有对前一个节点的引用。

在这种情况下，我们需要`O(N)`操作在最坏的情况下到达一个节点，但是插入和移除操作可以在常数时间内完成。

我觉得很自然的会想到一个“完美的数据结构”，让我们在不变的时间内做出这三个运算。可悲的是，这样的结构并不存在，但我在两个相反的极点之间找到了一个中间点。

数组的“问题”是它们维护对所有元素的引用。这允许我们用相同的运算量检索任何元素，不管元素在哪里。

但是维护这些引用使得插入和删除如此昂贵。

对于链表，我们只维护对第一个和最后一个节点的引用，每个节点都有对其邻居的引用。因此，当插入或删除一个新元素时，我们只需要改变几个引用。

但是缺少引用是我们不得不花费如此多的操作来在最坏的情况下得到一个元素的原因。

从这个角度来看这个问题，在引用数量中找到一个中间点的想法似乎很自然。如果我们维护对链表中`sqrt(N)`节点的引用，而不是只引用第一个和最后一个元素，会发生什么？

这允许我们有一个长度为`sqrt(N)`的列表，使得实际列表中每个节点之间的距离为`sqrt(N)`。有了这些，我们就可以在`O(sqrt(N))`中做每一个操作(索引、插入和删除)。

如果你想看更多关于这个结构的细节和它的 Lisp 实现，你可以在这里做。

我也在我的个人博客中写了一篇关于这件事的文章。

## 结论

我们已经看到了两个例子，说明了如何将现有的解决方案结合起来，得到另一个具有它们各自优点的解决方案。我的目的是向你展示这种思维方式，而不仅仅是具体的例子。

请注意，在 Dijkstra 的想法的情况下，我们可以实现最快的解决方案的时间和朴素算法的存储复杂性。在第二个例子中，我们只是得到了一个中间点，所以最快的解决方案仍然更快，内存更便宜的解决方案仍然更便宜。

但新的结构就像一名十项全能运动员——它在每一个方面都很好，但在任何一个方面都不是最好的。

所以不要试图寻找银弹——记住没有免费的午餐。即使是 Dijkstra 的想法也有难以实施和理解的缺点。

希望你从这篇文章中学到了一些东西。你可以在我的[个人博客](https://jj.hashnode.dev)和[推特](https://twitter.com/josejorgexl)上关注我，找到更多类似的内容。