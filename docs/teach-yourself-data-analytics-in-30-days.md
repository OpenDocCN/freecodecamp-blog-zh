# 30 天自学数据分析

> 原文：<https://www.freecodecamp.org/news/teach-yourself-data-analytics-in-30-days/>

你可以通过 30 天的实践学习数据分析的基础知识。

我们刚刚在 freeCodeCamp.org YouTube 频道上发布了一门数据分析课程。该课程包括一个 40 分钟的视频，以及一个网站和 Jupyter 笔记本。如果您遵循这些课程资源中的计划，您可以在 30 天内学会数据分析。

大卫·克林顿开发了这个课程。David 写了许多受欢迎的技术书籍，并创建了许多有用的视频课程。

该课程旨在对基于 Python 的数据
分析进行快速而深入的介绍。目标是让用户对 Python 的工作原理有一些基本的了解，以便他们能够自信地找到和操作数据源，并使用 Jupyter 环境从他们的数据中获得洞察力。本课程将展示有效的分析方法，但并不试图面面俱到。

这门课程的唯一先决条件是对 Python 编程有一个基本的了解，或者至少了解编程的一般工作原理。

以下是本课程涵盖的主要主题:

*   安装 Python 和 Jupyter
*   与木星环境合作
*   查找数据源和使用 API
*   使用数据
*   绘图数据
*   理解数据

你可以在 freeCodeCamp.org YouTube 频道观看下面的完整课程或[。](https://www.youtube.com/watch?v=jcTj6FgWOpo)

请务必查看相关网站:[https://stories.thedataproject.net/](https://stories.thedataproject.net/)

[https://www.youtube.com/embed/jcTj6FgWOpo?feature=oembed](https://www.youtube.com/embed/jcTj6FgWOpo?feature=oembed)

### 完整抄本

(注:自动生成)

大卫·克林顿撰写并创作了许多流行的技术书籍和视频课程。

本数据分析课程、附带的网站和 Jupyter 笔记本将帮助您在 30 天内学会数据分析。

欢迎来到我的课程，我真的很高兴有你在这里。

我更高兴的是，你已经决定加入数据分析党。

我是谁，我写了十几本关于 Linux 和 AWS 管理、数字安全的书，以及几十门关于 Pluralsight 的课程。

我在自由代码营新闻网站上也有很多文章。

但我只是写些东西。

希望当你看完这些内容后，你会出去用数据来改变世界。

既然你已经看到了我的声明，这将只需要你 30 天，我应该解释这实际上是要向你展示你将需要找到和操作原始数据的工具，并使用各种图形工具来帮助你理解和解释它。

但是不要期望我们在这里涵盖完整的数据科学课程，包括单变量和多变量微积分、算法问题解决，甚至机器学习。

那将需要更多的时间和努力。

如果这是你所追求的，请查看免费代码营正在上线的新数据科学内容，还有一些东西你不会从这些视频体验中获得。

一旦你看完了整个课程，你可能仍然不能自己做很多事情。

实际动手经验的价值是你犯的错误，你知道，错过键入语法，没有正确理解你的代码在做什么，或者没有考虑到环境特定的限制。

诊断和解决这些错误是你真正开始掌控和完成大事的地方。

那么你将从哪里获得这种体验呢？如果你雄心勃勃，而且你自己也有令人兴奋的项目想法，那就想尽一切办法去尝试吧。

但是如果你认为你仍然需要一些指导，那么我已经在我的故事 dot 数据项目 dotnet 网站上有了你应该需要的一切，你可以在那里找到的八个数据故事中的每一个中完成练习。

如果你正在寻找一项特定的技能，下面的学习目标索引会直接指引你找到任何人都可以免费获得的那一章。

如果你碰巧喜欢用一本真正的书，你可以购买相同格式的内容。

但是不要认为免费网站缺少了什么。但是现在，让我们来谈谈数据分析工具。

消费数据的方式有很多种，您选择的方式将反映您的特定需求，以及您对各种技能的适应程度。

你可能已经知道，电子表格不仅仅是花哨的计算器或记录家庭预算数字的地方。

它们还具有强大的功能、外部集成和绘图能力。

Tableau Splunk 或微软的 Power BI 等企业优势工具也非常适合处理数据和可视化见解，然后您可以与团队成员分享这些数据和见解。

那么 Python 有什么大不了的呢？嗯，Python 生态系统比那些专门的构建工具要广泛得多。

Python 社区提供了各种有用的特定于数据的库和模块。

当您让 Python 与您的数据发生冲突时。

您已经获得了完整的工业级编程语言的所有资源。

不是你能用它做什么。

这就是挑战。

是发现你做不到的事情。

好吧，但是木星呢？Jupiter 是一个开源平台，您可以在其中加载数据并执行 Python 代码。

很像微软 Visual Studio 之类的编程 Id。

虽然 Jupyter 笔记本可以用于越来越多的语言，可以用于你可以想象的许多任务，但它最出名和最受欢迎的是作为 Python 数据英雄的主机。

曾几何时，您为程序编写的代码行将被保存到一个文本文件中，该文件的名称以点 p y 后缀结尾。

当你想让它运行你的代码，看看事情是如何进行的。

您可以从命令行或强大而复杂的源代码编辑器(如 Visual Studio)中完成。

但是要想成功，一切都必须成功。

当事情不按规格进行时，这将使故障诊断更加困难。

但这也会让我们更难仅仅为了看看会发生什么而玩弄具体的细节。

这也使得在互联网上共享你的代码的实时版本变得困难。

我们很快就会看到，Jupyter 笔记本可以让你一次运行一行代码，或者全部运行。

这种灵活性使得理解您的代码以及在出现问题时解决问题变得更加容易。

顺便说一下，笔记本是基于 JSON 的文件，它可以有效地将任何面向数据的编程代码的处理环境从您的服务器或工作站转移到您的 web 浏览器。

您可以将 Jupiter 下载到您的 PC 或私人服务器上，并通过任何带网络接入的浏览器访问该界面。

或者，你可以在第三方托管服务上运行笔记本，如谷歌的核心实验室，或者像亚马逊的 Sage maker studio notebooks 这样的云提供商，或者微软的 as your notebook。

木星有三种口味。

你最有可能遇到的两个是经典笔记本和较新的木星实验室。

两者都可以很好地在你的浏览器中运行。

但是 Jupiter lab 提供了更多的扩展，可以让你在一个浏览器标签中处理多个笔记本文件和终端访问。

在本课程的演示中，我将使用传统的笔记本电脑环境，但是在不同版本之间转移笔记本电脑通常没有问题。

第三个要完成的任务是木星枢纽。

这是一个服务器版本，旨在为多个用户提供经认证的笔记本访问，使用 littlest Jupiter hub，您可以从一台云服务器上为多达 100 名左右的用户提供服务。

对于涉及服务器集群的大型部署，使用 Kubernetes 版本可能会更好，该版本被称为 zero to Jupiter hub with Kubernetes。

但所有这些都超出了本课程的范围。

我们下一步的工作是建立我们的工作环境。

假设您已经决定在自己的机器上托管 Jupiter，那么您需要安装 Python。

好消息是，大多数操作系统都预装了 Python，您可以通过打开命令提示符并键入 Python dash dash version 或有时 Python three dash dash version(Python 三个 dash 版本),来确认您已经安装了 Python 的最新版本，您可能会看到类似这样的内容。

只要确保你已经安装了 Python 3，而不是已经过时且不安全的 Python 2。

如果您确实需要手动安装 Python，您最好使用 Python 官方文档，这将是最完整和最新的可用资源，可以在任何操作系统上工作。

值得注意的是，并不是所有的 Python 版本，即使是来自 three point x 的版本，都一定会按照您所期望的方式运行。

例如，您可能会发现您需要一个为 3.9 版本编写的库。

但是没有办法让它在你的 3.7 系统上工作。

将您的系统版本升级到 3.9 可能对您有好处。

但它也可能导致一些意想不到的不愉快的后果。

很难知道您的核心操作系统何时也需要某个特定的 Python 库。

如果你使用原始版本的库，他可能会禁用操作系统本身。

也不要以为不会发生。

就在几个月前，我把自己的 O 也弄成了那样。

一种解决方案是在一个特殊的虚拟环境中为您的项目运行 Python，这个虚拟环境与您的大型操作系统隔离开来。

这样，您可以安装所有您喜欢的库和版本，而不必担心损坏您的工作系统。

你可以使用一个完整的虚拟容器运行 Docker，或者我更喜欢 LX D image，或者在一个独立的 AWS 云实例上。

但是你也可以使用 pythons 自己的 v n 模块，你可以阅读官方文档来了解特定于你的主机操作系统的虚拟环境指令。

无论您选择哪个版本的 Jupiter，如果您决定在本地安装并运行它，Jupiter 项目官方推荐通过 Python Anaconda 发行版及其二进制包管理器 conda 来实现。

不同的操作系统主机有不同的操作指南，但是这个官方页面是一个很好的起点。

正如您所看到的，Python PIP 包管理器也是一个选项。

一旦所有这些都完成了，你应该能够在你的浏览器中打开一个笔记本并开始工作。

对我来说，笔记本最强大的功能是你可以在单个单元格内运行你的代码子集。

这使得将长而复杂的程序分解成易于阅读和执行的片段变得更加容易。

选中一个单元格。

单击 Run 按钮将只执行该单元的代码。

请注意左边的框是如何获得一个数字来表示执行的顺序位置的。

随着您对 Jupiter 越来越熟悉，您可能会养成使用 Ctrl 和 enter 执行单元格的习惯，而不是单击鼠标，您可以通过单击加号按钮在当前选择的单元格之后插入一个新的单元格。

如您所料，上下箭头可以上下移动单元格。

默认情况下，单元格被格式化为处理代码，在我的例子中是 Python，但它们也可以设置为 markdown，这对于记录您的笔记本或使新的部分更容易找到很方便。

例如，markdown 中的一个 hashtag 表示一个顶级选择标题，执行该单元格将打印文本以匹配您的格式化指令。

不同版本的 Jupiter 会有不同的按钮位置和外观，但是所有的基本功能都是通用的。

无论您的代码创建什么值，都将保留在内核内存中，直到某个特定单元或整个内核的输出被清除。

这使您可以重新运行前一个或后一个单元格，以查看更改可能产生的影响。

这也意味着重置您的环境来一个完整的重新开始就像选择重启内核和清除所有输出一样简单。

并非所有 Python 功能都是现成可用的。

有时，正如您刚才看到的，您需要告诉 Python 通过代码中的声明来加载一个或多个模块。

但是有些模块需要从主机命令行手动安装，然后才能导入。

对于这种情况，Python 推荐他们的安装程序 Pip，或者在某些情况下，推荐 Anaconda 发行版中的 conda 工具。

您可以在有用的 Python 文档站点中阅读更多关于使用 PIP 对 Python 系统进行正确维护和供给的信息。

好了，这就是我们开始真正工作的地方。

我们将前往互联网寻找可靠的数据，帮助我们回答现实世界的问题。

我们将使用一个公共 API 来获取数据。

然后，我们将检查数据，了解其当前的格式，以及如何修复它。

在应用必要的格式后，我们的代码可以愉快地阅读它，将多个数据集合并在一起，这样我们就可以寻找相关性，然后用图形工具进行实验，找到一个以最易懂的方式表示我们的数据的数据集。

我们要解决的问题是什么？我很想知道在过去的 20 年里，美国工人的工资是否平均上涨了，假设工资上涨了，我还想知道他们口袋里的额外收入是否也提高了他们的实际生活水平？为了回答这些问题，我们将访问由美国政府劳工统计局收集和维护的两组数据。

劳工统计局通常被称为 BLS，它的许多优点之一是提供了一个从我们的 Python 脚本中访问的 API。

要做到这一点，您需要知道与特定数据序列相匹配的 BLS 端点地址，您需要 Python 代码来发起请求，对于更大的请求量，还需要一个 BLS API 键。

获得你需要的系列端点地址可能需要在 BLS 网站上做一些挖掘。

然而，最流行的数据集可以通过一个页面访问。

这向你展示了它的样子，包括像 lns 这样的端点代码，一个 1 和一大堆 0，对于平民劳动力来说，你也可以在这个页面上搜索数据集。

例如，搜索一台计算机，你会看到一个列表，其中包括德克萨斯州圆石市奥斯汀市 11 级计算机和数学职业诱人的平均时薪。

通过扩展该选择，您将发现的信息将包括其系列 ID，这是终点，因为我知道您几乎无法抑制您的好奇心。

我将点击并向您展示在 2019 年，德克萨斯州圆石市奥斯汀数学专业的 11 级计算机预计每小时可赚 51.76 美元。

那么，如何将这些系列 id 转换成 Python 友好的数据呢？手动编写 get 和 put 请求是非常挑剔的，在完全正确之前需要进行大量的尝试。

为了避免这一切，我决定使用名为 BLS 的第三方 Python 库。

那可通过我们所有的 share roses GitHub repo 获得，你在你的主机上安装这个库，使用 pip 安装 BLS。

这就够了。

既然我们在这里，我们不妨激活我们的 BLS API 密钥。

你在这个页面注册 API，他们会给你发一封电子邮件，里面有你的密钥和一个验证 URL，你需要点击它。

一旦你得到了你的密钥，你把它导出到你的 Linux 或 Mac OS 上的系统环境中，这将意味着运行这样的东西，其中你的密钥替换了我在这里使用的假密钥，我将使用 API 来请求美国消费者价格指数，CPI，以及 2002 年到 2020 年之间的工资和薪水统计数据。

CPI 是衡量一篮子基本消费品价格的指标。

这是生活成本变化的一个重要指标，而生活成本的变化又是经济总体健康状况的一个指标。

我们的工资数据将来自 BLS 就业成本指数，涵盖所有行业和职业的私营行业工人的工资和薪金。

乍一看，就业指数的增长表明大多数人的情况正在好转。

然而，孤立地看待平均就业工资趋势并不那么有用。

毕竟，如果你的基本开销仍然很高，那么最高的薪水也不会给你带来多少好处。

因此，我们的目标是提取 CPI 和工资数据，然后将它们关联起来，寻找模式。

这将向我们展示工资相对于成本是如何变化的。

现在，让我向你展示它实际上是如何工作的。

有了我们将要使用的两个数据集的有效端点，我们就可以开始挖掘 CPI 和就业黄金了。

导入这四个库，包括 BLS，将会给我们所有需要的工具。

pandas 代表 Python 的数据分析，这是一个将数据作为数据框使用的库。

在您学习处理大型数据集时，数据框可能是您将使用的最重要的结构。

NumPy 是一个针对大型数据数组执行数学函数的库。

map plot live 是一个用于在各种可视图形中绘制数据的库。

当导入一个库时，您可以为它指定一个您将用来调用它的名称。

你可以选择任何东西，但是 pandas 通常由 PD NumPy 表示为 NP，matplotlib 表示为 PLT，我还导入了我们之前安装的 BLS 库，将使用它的实际名称 BLS 来调用它。

我会处决那个牢房。

现在，我将 CPI 数据序列的 BLS 端点传递给 BLS 图书馆的 BLS get series 命令。

端点代码本身当然是从 BLS 网站上流行的数据集页面复制的，我将使用变量 CPI 将返回的数据序列分配给数据框，然后将数据框保存到本地 CSV 文件。

这不是必须的，但是您可能会发现当数据保存在本地时，处理数据会更容易。

接下来，我将使用 pan das PD read CSV 命令根据文件名加载新 CSV 文件中的数据。

我将把变量名 CPI data 赋给从另一端出来的新数据帧。

仅运行 CPI 数据将打印出数据帧的第一行和最后五行。

日期列包含月份和年份值。

第二列包含我们的实际数据。

我想简化标题，使它们更容易使用。

所以我将使用 pan das columns 属性，我肯定更喜欢这种方式。

然而，我们还需要看到工资数据，以了解格式化的用途是否与我们的 CPI 集兼容。

因此，我将使用 BLS 库提取工资数据系列，并将其分配给工资数据框。

同样，我将它保存到一个本地 CSV 文件中，并将该数据读入一个名为 df 的新数据帧中。

我将清理我的列标题，并使用 head 只打印前五行数据，您应该注意到两件事。

这些数据不是按月递增，而是按季度递增，但每三个月只有一个条目。

而且日期格式也不一样。

除了月份数字，还有第一季度或第二季度。

如果您希望 Python 在我们的两个数据集之间同步，我们需要做一些编辑。

我将通过用字符串 q 替换每个三月数据点(表示日期值中包含字符串破折号 03 的任何日期条目)来实现这一点。一个六月是包含破折号 06 的字符串，我们将得到 q2，依此类推。

正如您现在看到的，当我只打印日期列时，一些值已经更新为新的格式。

但其余的从这一点来看是不必要的，会给我们带来麻烦，所以我们必须把它们一起除掉。

为此，我将创建一个名为 New CPI 的新数据帧，并将旧 CPI 数据数据帧的内容读入其中。

但我将使用平移虚线字符串点包含函数来识别数据框中包含破折号的所有行。

通过指定 false，删除它们，我们将只剩下格式正确的季度数据点。

我说，我将把这个数据框保存到一个 CSV 文件中，注意我们是如何从 232 行减少到只有 77 行的。

就因为我偏执，我就创建一个新的数据框，叫新 df。

因此，如果我不小心弄乱了我们接下来要做的事情，我仍然可以使用旧的测向数据框架。我们的数据都整理好了，我们就可以开始分析了。

我们在这里遇到了一个大问题，CPI 集合中的数据来自绝对点值。

虽然工资是以衡量增长的百分比报告的，但没有办法准确地比较它们。

首先，我们工资数据的每一行都是当前工资率持续了整整 12 个月的那个季度的工资百分比。

因此，这些数值不仅与绝对 CPI 价格数据不一致，甚至在技术上也不符合它们自己的时间框架。

所以当我们得知 2002 年第一季度的失业率是 3.5%时。

这意味着，如果工资继续以当前第一季度的速度增长，整整 12 个月，年平均增长率将为 3.5%，而不是 14%，这意味着我们将不得不调整数据。

这是因为在 2002 年第一季度的三个月中，实际增长率不是 3.5%，而是只有那个数字的四分之一，即 0.8-75%。

如果我不做这种调整，而是继续将季度增长数据映射到季度 CPI 价格(即计算出的产出)，我们会认为工资增长如此之快，以至于与现实脱节。

现在，我应该警告你，解决这个兼容性问题将需要一些假的数学，我将每个季度的增长率除以 4，或者换句话说，我将假设这三个月工资的实际变化正好是报告的年增长率的四分之一。

我敢肯定这几乎肯定不是真的。

这是一种粗略的简化。

然而，对于我在这里试图描绘的大历史图景来说，这可能已经足够接近了。

现在，我们仍然会得到一个百分比数字，但我们与之比较的相应 CPI 数字也是一个点数字。

来解决这个问题。

我会再做一件赝品。

为了将这些百分比转换为与 CPI 值相匹配的值，我将创建一个函数，我将向该函数输入从 2002 年第一季度开始的 CPI 值 170 7.1。

那将是我的底线。

我将把这个变量命名为 new num。

对于每次迭代，该函数将遍历我的工资数据序列的行，我将把当前工资值 x 除以 400。

我从哪里得到的数字 100 只是把百分比转换成 3.5，等等，转换成小数 0.035。

这四个人将把年或 12 个月的利率减少到三个月的季度利率，把它转换成可用的数字，乘以新数字的当前值，然后把新数字加到乘积上。

这应该给我们一个经过相关工资增长百分比调整的原始 CPI 值的近似值。

但当然，这不会是一个在现实世界中有任何直接对应的数字。

相反，正如我所说的，它是这个数字的任意近似值。

但是，我认为它已经足够接近我们的目的了。

花点时间通读一下这个函数。

Global new num 将变量声明为全局变量。

这使得我可以用函数输出替换 new num 的原始值，因此下一行中的百分比将由更新后的值进行调整。

还要注意字符串是如何被忽略的。

最后，请注意更新后的数据系列将如何填充新的工资数据变量。

让我们检查一下新数据是否看起来不错。

我们的下一个任务将是合并我们的两个数据框，然后绘制它们的数据。

不要走开。

剩下的，我们需要合并我们的两个数据系列，以便 Python 可以比较它们。

但是因为我们已经完成了所有的清理和操作，这将会很顺利。

我将创建一个名为 merge data 的新数据框，并向它提供这个 PD merge 函数的 URL，我只需提供两个数据框的名称，并指定 date 列应该是索引。

这并不难。

让我们来看看。

我们的数据都在那里，我们可以直观地浏览 CPI 和 wages 列，寻找任何不寻常的关系。

但这违背了重点。

Python 数据分析就是让我们的代码为我们做这些。

让我们画出这个东西。

在这里，我们将告诉 plot 使用我们的合并数据框合并数据并创建一个条形图。

因为这里有大量的数据，我将用手动固定的大小值来扩展图表的大小，我将 x 轴设置为使用日期列中的值。

同样，因为它们太多了，我将把标签旋转 45 度，使它们更易读。

最后，我将设置 x 轴和 y 轴的标签。

这是从另一端出来的，因为拥挤，不太容易看。

但是你可以看到橙色的工资条在很大程度上高于蓝色的 CPI 条。

这意味着工资正经历着比 CPI 更高的增长率，我们稍后会尝试分析其中的一些数据，有没有更简单的方法来显示所有这些数据，当然有，我可以将实物的价值从条形改为线形，情况会立即改善。

下面是新代码如何作为线图和网格工作。

Python 及其相关库使我们能够使用比条形图和折线图更广泛的绘图工具。

我们在这里只探讨其中的两种，散点图和直方图。

我们还将谈一谈回归线是如何工作的，以及它们能向我们展示什么样的洞察力。

我们将从散点图开始。

这段代码来自我的自学数据分析网站上的产权和经济发展章节，你可以在那里补上背景知识。

但你看到的代码来自两个数据源，世界银行对各国人均国内生产总值的衡量，以及美国传统基金会的经济自由指数数据

rg 站点，我将两个数据框中的数据合并到这个称为合并数据的数据框中，我将创建一个简单的散点图。

通过这一行命令，我们可以清楚地看到一个模式，人均国内生产总值越高，意味着一个国家产生的经济活动越多，x 轴上的点越向右，一个国家的点就可能下降。

越靠右，经济自由度得分越高。

当然，我们的数据中存在异常。

有些国家的位置似乎超出了所有其他国家的范围，如果我们能够以某种方式看到这些国家，那就太好了，如果我们能够量化我们两个值之间的精确统计关系，而不是必须目测猜测，那就更好了。

我们将从可视化数据中的异常开始。

让这一切成为现实。

所有重要的另外两个库是 plotly 工具家族的一部分，您可能需要使用 pip install plotly 在您的主机上手动安装它们。

在这些起作用之前。

从那里，我们可以运行 p x 散点图，并将其指向我们的合并数据数据框，将分数列与 x 轴关联，将值与 y 轴关联。

所以我们可以将鼠标悬停在一个点上，查看它所代表的数据。

我们将添加悬停数据参数，并告诉它包括国家和分数数据。

这一次，当您运行代码时，您会得到同样漂亮的图形。

但是如果你将鼠标悬停在任何一个点上，你也会看到它的数据值。

在这个例子中，你可以看到小国卢森堡的经济自由度得分为 75.9

人均国内生产总值超过 121000 美元。

你同样可以在图表的两端选择其他国家，我们可以通过添加回归线来了解我们的值之间的统计关系，数据的度量是 R 平方值。

我们已经看到了我们的图如何显示一个明显的向右上方的趋势。

但是我们也看到了异常值。

我们能确信异常值是例外，并且我们的两个数据源之间的总体关系是合理的吗？

在某个时候，我们只能根据对图表的视觉观察做出这么多假设，我们需要硬数字来描述我们正在看的东西。

简单的线性回归分析可以给我们一个因变量和数据模型之间关系强度的度量。

r 的平方是一个介于 0 和 100%之间的数字。

100%表示完全符合。

当然，在现实世界中，100%适合几乎是不可能的。

您将在您正在处理的数据的上下文中判断您的模型或假设的准确性，您如何在熊猫图中添加回归线呢？和往常一样，有许多方法可以实现它，我喜欢简单，而 O LS 趋势线方法就是这么简单，只需在我们已经使用的代码中添加一个趋势线参数。

就是这样。

哦 LS 顺便说一下，代表普通最小二乘，是 a，是一种线性回归。

这是我们回归线的样子。

当我悬停在线上时，我显示 R 的平方值为 0.550451。

或者换句话说，在 35%左右。

就我们的目的而言，我认为这是一个很强的相关性。

直方图是一种绘图工具，可以将数据分解成多个条块。bin 实际上是数据集之间的统计适当间隔的近似值。尝试猜测概率密度函数 PDF，它将最好地代表您实际使用的值。

但是它们可能不会完全按照您的想法显示，尤其是当您使用默认值时。

我将举例说明这是如何工作的，或者实际上是如何不工作的。

利用网站上“生日能让运动员成为精英”一章的数据。

正如你在那里看到的，我已经收集了大约 1100 名当前 NHL 玩家的出生日期的半官方的 NHL API。

我的目标是将他们的出生日期在所有 12 个月中的分布可视化，以查看他们的出生是否集中在一个特定的年度季节。

当我使用直方图显示数据时，我们没有看到预期的模式。

事实上，这种模式并不能真正代表现实世界。

这是因为直方图非常适合通过将数据点分组到箱中来显示频率分布。

这可以帮助我们快速地可视化一个非常大的数据集的状态，在这种情况下，粒度精度会成为障碍，但对于像我们这样的用例来说，这可能会产生误导。

因为我们在寻找事件到日历日期的字面映射。

即使将 bin 数量设置为 12 来匹配月数也无济于事，因为直方图不一定会坚持那些精确的边界。

这里我们真正需要的是一个普通的条形图，其中包含了我们的值计数数字，我将把值计数的结果传输到一个名为 df one 的数据帧中，然后绘制成一个简单的条形图。

在下一个模块中，我们将讨论如何理解我们的数据可视化，以及如何将我们在 Jupyter 笔记本上看到的内容与实际发生的事情相结合。

在现实世界中。

敬请关注。

我们应该在这里做数据分析，比如盯着漂亮的图表可能不是重点。

例如，我们在前一章中绘制的 CPI 和工资数据集向我们展示了一个清晰的总体相关性。

但是有一些视觉上可识别的异常。

除非我们能够将这些异常现象与历史事件联系起来，并在历史背景下解释它们，否则我们无法从我们的数据中获得全部价值。

但是，即使在去那里之前，我们也应该确认我们的图实际上在它们的数据源的上下文中是有意义的。

以我们在 BLS 的例子为例，让我们用图表来比较操纵前后的 CPI 和工资数据。

这样，我们就可以确定我们的数学，尤其是我们的假数学，没有扭曲得太严重。

这是我们用原始数据绘制的 CPI 数据。

这当然是一个繁忙的图表，但你可以清楚地看到被一些突然的跳跃打断的平缓上升的斜坡。

接下来，我们将看到相同的数据，在去除每四个月中的三个数据点后，相同的起伏仍然可见。

考虑到我们的总体目标。

我认为我们的转型是成功的。

现在，这里的工资数据怎么样，因为我们从百分比转移到货币，转换更具侵入性，虚假陈述的风险也更大。

我们还需要考虑百分比和绝对值的不同显示方式。

这是原始数据。

注意没有一致的曲线，向上或向下。

这是因为我们衡量的是每个季度的增长率，而不是增长本身。

现在把它和这个工资数据的折线图比较一下，这个折线图已经被转换成基于货币的值了。

你看，平缓的曲线有一定的道理，它毕竟是关于真实的增长，而不是增长率，但也有可能识别出曲线变陡的一些地方和曲线变平滑的一些地方。

与基于百分比的数据相比，为什么斜率如此平滑？看 y 轴标签。

指数图以 180 和 280 之间的点来度量。

而百分比图从零到 3.5。

不同的是规模。

总而言之，我相信我们可以安全地得出结论，我们产生的结果与我们的源数据非常匹配。

为数据建立某种历史背景需要寻找异常，并将它们与已知的历史事件相关联。

这是我在网站上的工资和 CPI 现实核查章节中详细阐述的内容。

如果你感兴趣，我相信你会自己完成这些材料的。

但是我想你在这里已经看到了足够多的东西，可以了解绘制正确的可视化是如何有帮助的。但是，正如我已经多次提到的，我们已经结束了这门特定的课程，完整的课程可以在我的数据项目网站上获得，非常欢迎你加入到所有酷孩子的行列中来，如果你有什么要补充的，请保持联系。

最重要的是要认识到，本课程的结束并不意味着你的数据分析教育的结束。

看着我平静地执行漂亮、干净的代码示例并不是真正的学习。

除非你是一个非常特殊的天才，否则你不会开始理解所有这些是如何真正工作的。

直到你投入进去，自己解决问题。

我说有价值的事情。

但我真正的意思是，事情不值得去经历，因为错误和挫折才是最好的老师。

不要想象我的 Python 代码是在一个安静的下午才出现的。

当我啜饮美味的热咖啡时。

首先，我不喝咖啡。

但更重要的是，这里一点也不安静。

在事情开始成形之前，有羞辱性的失败、重新制定和无数次的堆栈溢出。

但是，我面对和克服的问题越多，这个过程在我脑海中就越深刻，我就越擅长。

所以你要为未来的艰难时刻做好准备。

在你们离开继续你们的一天之前，让我们花一点时间回顾一下我们在这里看到的一切。

我们谈到了使用 Jupyter 笔记本电脑的许多方式，包括像 Google 的 Collaboratory 这样的在线平台，以及在本地托管 Jupiter 实验室或塑料笔记本电脑，向我们介绍了 Jupiter 环境，了解了 cells 内核和操作环境。

我们看到了如何通过公共 API 查找数据，以及如何将 API 凭证集成到 Python 环境中。

Python 库和模块是我们的下一个焦点，包括如何导入适当的库来允许我们有效地清理和操作我们的数据。

最后，转向一些实际的数据分析。

我们学习了一些绘图的基础知识，包括散点图、回归线和直方图。

我们结束了合唱，快速讨论了如何使用我们的数据可视化来整合我们对现实世界的见解。

我希望这对你有所帮助，我邀请你在我的主网站上查看我的其他一些内容。

保重。