# 如何简化 Kubernetes 故障排除

> 原文：<https://www.freecodecamp.org/news/how-to-simplify-kubernetes-troubleshooting/>

诊断和解决 Kubernetes 中的问题可能相当具有挑战性。Kubernetes 毕竟[是一个复杂的系统](https://kubernetes.io/docs/concepts/)。

即使在小型 K8s 集群、节点和容器中解决问题也可能很棘手，并且通常很难识别和解决问题。一个问题甚至不总是容易跟踪的，它可能是一个或多个 pod、单个容器、控制器、控制面板或多个组件中的问题。

正如您所料，当您处理涉及大量微服务的大规模生产环境时，复杂性会呈指数级增长。

这些微服务通常由不同的开发团队创建。也有这样的例子，这些微服务是由不同的团队协作构建的，但是是在一个公共的 K8s 集群上。

在这种情况下，可能会混淆谁负责对什么进行故障诊断。

但是不要担心——在以下几点的帮助下，您可以避免将 Kubernetes 的故障排除变成一个无法管理的混乱局面，并避免浪费资源。

## 增加可见性

Kubernetes 故障排除中最重要的[点之一是需要提高可见性。](https://komodor.com/learn/kubernetes-troubleshooting-the-complete-guide/)

来自 Kubernetes 安全状况 2020 调查的数据显示，75%的 Kubernetes 用户认为可见性是必不可少的，因为快速确定和检查一个组织随着时间的推移已经部署的所有东西可能是乏味且具有挑战性的。

### 为什么在 K8s 中能见度很重要？

增强的 K8s 可见性确实有助于您获得运营和安全洞察。它还可以实现以下目标:

*   **确保合规。**当组织遵循既定的标准或指导方针时，卷入复杂或令人费解的场景的可能性就会降低。这也意味着故障排除变得更加容易。
*   **确定适当的交通流量**。特别是服务或微服务之间的数据流量，就像是对 K8s 系统健康状况的描述。交通必须去它应该去的地方。否则，将会出现严重的故障和关键问题。
*   **了解 K8s 环境中正在运行什么，并确定它们的配置是否正确。**如果您不熟悉您的 K8s 环境，进行任何故障排除都是极其困难的。
*   **预测季节性需求**。通过对 Kubernetes 的适当了解和理解，您可以看到资源使用的趋势或模式。这有助于您进行预测，这对故障排除也很有用。
*   使资源得到有效利用。更高的可见性使您能够确定相对于延迟和性能历史，您是否使用了正确的资源量。
*   **高效的故障排除。**清楚地了解 Kubernetes 应用环境中发生的一切最终会带来更好的故障排除结果，因为更容易找到您在应用和微服务方面遇到的问题的根本原因。

### 如何提高你的 K8s 知名度

如果您想提高 K8s 的可见性，您需要收集两种类型的数据:实时数据和历史数据。

实时数据是识别和解决当前问题所必需的。历史数据作为基准活动的基础，用来衡量被认为是常规或正常的事情。

这两种类型的数据在故障排除中都很有用，当它们提高您的 Kubernetes 可见性时会变得更加有用。

您可以通过创建一种高效获取和分析实时和历史数据的方法来提高可见性。您还可以通过使用有助于增强部署和监控的工具来提高可见性。

有许多 Kubernetes 工具可以实现实时监控、控制和跟踪。这些工具可以为您提供强大的状态更新页面、指标和 OpenTracing 功能，包括对 LightStep 和 Datadog 等可观察性平台的支持。

## 建立有组织的高效故障管理

仅仅找到缺点是不够的。你还需要有一个有组织和有效的方式来管理问题。这有助于防止(或更快地解决)将来类似的问题。

正如我们刚刚讨论的，Kubernetes 可见性的提高有助于您更有效地使用资源。您应该利用这种效率优势，想出一种有组织的、高效的方法来管理您的 Kubernetes 错误。

对于初学者来说，要特别注意掌握常见的 K8s 错误，如下所述。在许多情况下，这些问题只是一些常见或简单的错误，许多 K8s 开发人员倾向于过度分析。

### Common Kubernetes Errors

[CreateContainerConfigError。](https://datafloq.com/read/how-debug-createcontainerconfig-error/17789)此故障通常源于缺少 ConfigMap 或 secret(包含登录凭证等敏感数据的 K8s 对象)。

该问题可能是容器注册表中的身份验证问题，或者是使用了错误的图像名称或标记。您可以通过运行适当的命令来识别这些问题。

**CrashLoopBackOff。**当无法在节点上安排 pod 时，会出现此错误。这可能是因为节点上没有足够的资源来运行 pod，或者 pod 未能装入请求的卷。

Kubernetes 节点未准备好。当一个工作节点终止或崩溃，导致驻留在关闭节点上的所有有状态 pod 不可用时，就会发生这种情况。

这通常会在一段时间后自行解决。但是，如果时间很重要，您将需要在不同的运行节点上重新安排有状态的 pod。

对于其他问题，标准的故障诊断通常需要几个步骤。对于 K8s pods 故障诊断，您通常需要:

*   检查 kubectl describe pod 命令的输出，
*   检查 pod 描述中的错误，
*   检查 API 服务器和本地 pod 清单之间的不匹配(以及通过 pod 日志对其他 pod 问题的诊断)，以及
*   在节点上执行容器执行调试、临时调试容器调试和调试窗格命令。

对于 K8s 集群，您需要查看基本的集群信息，检索集群日志，并根据您发现的问题实现解决方案。

例如，要解决 API 服务器虚拟机崩溃或关闭的问题，您需要重启 API 服务器虚拟机。这种解决方案同样适用于控制平面服务崩溃和 Kubelet 故障。

您应该有预定义的工作流来指导您对各种问题的响应。同样，排除 Kubernetes 故障并不像听起来那么简单。有备忘单没什么不好，尤其是当你处理不常见的问题时。

## 使用 Kubernetes 故障排除解决方案

对于许多公司或团队来说，使用 K8s 故障排除服务可能是处理 Kubernetes 问题的最佳方式。

并不是每个团队都有顶级的 Kubernetes 专家，他们可以在问题出现时立即解决问题。并不是每个人都有合适的工具和系统程序来处理容器、pod、集群或节点问题。

故障排除解决方案可以提供一个统一的平台来跟踪 K8s 活动，从而更容易跟踪问题的根源。

例如，通过提供全面的时间表，这样的系统可以提供一种有效的方式来提高 K8s 的可见性。或者它可以有组织地显示所有代码和配置修改、pod 日志、部署状态、警报、代码差异和其他详细信息。

此外，高级 Kubernetes 故障排除服务旨在洞察服务依赖性。它们使得理解整个组织中正在发生的跨服务变化变得容易。

它们可以提供一些有用的细节，说明某些变化之后会发生的连锁反应，帮助您识别并最终解决问题。

## 概括起来

说 Kubernetes 的故障排除可以简化似乎是一种矛盾。承诺一种真正简化的方法来处理 K8s 问题是不是太过分了。

但是，确定一些方法使故障排除过程不像通常那样复杂和繁琐，肯定不是不可能的。